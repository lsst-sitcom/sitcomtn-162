{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395275ca-ca04-40a8-9529-81a813c885f9",
   "metadata": {},
   "source": [
    "# A360 Metadetection Shear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99756233-b748-4c6c-aa98-9428b51f3625",
   "metadata": {},
   "source": [
    "Contact author: Miranda Gorsuch\n",
    "\n",
    "Create a shear profile for A360 using cell-based coadds and `metadetection`. Many parts are from the [Shear profile around A360 using ComCam HSM shapes](https://github.com/lsst-sitcom/comcam_clusters/blob/main/ACO360_WL_HSCcalib_CLMM.ipynb) notebook, especially the identification of red sequence galaxies and use of CLMM to create the tangential shear plot.\n",
    "\n",
    "Last working weekly: `w_2025_41`\n",
    "\n",
    "Container Size: 16 GB (large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363040bb-aa56-4815-9c09-56e4cc677e4e",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5827c89-8fa5-42a9-a6d5-f9fcc292732f",
   "metadata": {},
   "source": [
    "## Imports & Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839205e9-57a1-4070-8e08-2ed667bdc6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locally install modeling packages (only do once, if not already installed)\n",
    "# !pip install pyccl\n",
    "# !pip install clmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0261814-f200-4828-a7a7-683c066cdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.daf.butler import Butler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.table import Table, vstack\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import gc\n",
    "\n",
    "from lsst.skymap import Index2D\n",
    "import lsst.afw.geom as afwGeom\n",
    "import lsst.afw.math as afwMath\n",
    "import lsst.afw.image as afwImage\n",
    "import lsst.geom as geom\n",
    "\n",
    "# for stats control\n",
    "from lsst.drp.tasks.assemble_cell_coadd import AssembleCellCoaddTask\n",
    "import lsst.meas.algorithms as meas\n",
    "\n",
    "from lsst.afw.geom.ellipses import Quadrupole, SeparableDistortionTraceRadius\n",
    "\n",
    "from numpy.linalg import inv\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2, norm\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "import healsparse as hsp\n",
    "\n",
    "import qp\n",
    "import pickle\n",
    "\n",
    "import clmm\n",
    "from clmm import GalaxyCluster, ClusterEnsemble, GCData, Cosmology\n",
    "from clmm import Cosmology, utils\n",
    "\n",
    "cosmo = clmm.Cosmology(H0=70.0, Omega_dm0=0.3 - 0.045, Omega_b0=0.045, Omega_k0=0.0)\n",
    "h = 0.7\n",
    "cl_z = 0.22\n",
    "%matplotlib inline\n",
    "\n",
    "# Position in degrees of the BCG for A360\n",
    "ra_bcg = 37.865017\n",
    "dec_bcg = 6.982205\n",
    "\n",
    "REPO = '/sdf/data/rubin/repo/main/'\n",
    "butler = Butler(REPO)\n",
    "registry = butler.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a5696-707d-40ff-9cf6-7a571cdb1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_type = 'gauss'\n",
    "\n",
    "# with noise correlations\n",
    "if meas_type == 'wmom':\n",
    "    collection = 'u/mgorsuch/metadetect/a360_3_band/noise/20250827T213552Z'\n",
    "elif meas_type == 'gauss':\n",
    "    collection = 'u/mgorsuch/metadetect/a360_3_band_gauss/noise/20250827T214428Z'\n",
    "elif meas_type == 'pgauss':\n",
    "    collection = 'u/mgorsuch/metadetect/a360_3_band_pgauss/noise/20250827T215647Z'\n",
    "else:\n",
    "    print(\"Not an available measurement type\")\n",
    "\n",
    "cell_collection = 'u/mgorsuch/ComCam_Cells/a360/corr_noise_cells/20250822T224002Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d954d-d8b4-47d9-88bc-9264fe851bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T20:05:29.301609Z",
     "iopub.status.busy": "2025-09-05T20:05:29.301281Z",
     "iopub.status.idle": "2025-09-05T20:05:29.307722Z",
     "shell.execute_reply": "2025-09-05T20:05:29.306789Z",
     "shell.execute_reply.started": "2025-09-05T20:05:29.301584Z"
    }
   },
   "source": [
    "The functions `detect_sig` and `gal_den_profile` are based on https://github.com/lsst-sitcom/comcam_clusters/blob/main/ACO360_WL_HSM_HSCcalib_CLMM_forTN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38582d-c93c-4b2b-a583-b0ba25358d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get detection significance from a GC Object\n",
    "def detect_sig(gc_object):\n",
    "    gamma_t = gc_object.profile['gt']\n",
    "    sigma_t = gc_object.profile['gt_err']\n",
    "    gamma_x = gc_object.profile['gx']\n",
    "    sigma_x = gc_object.profile['gx_err']\n",
    "    \n",
    "    # Compute chi-squared statistic (compared to null hypothesis)\n",
    "    chi2_stat_t = np.sum((gamma_t / sigma_t)**2)\n",
    "    chi2_stat_x = np.sum((gamma_x / sigma_x)**2)\n",
    "    dof = len(gamma_t)\n",
    "    \n",
    "    # Compute p-value from chi-squared distribution\n",
    "    p_value_t = 1 - chi2.cdf(chi2_stat_t, dof)\n",
    "    p_value_x = 1 - chi2.cdf(chi2_stat_x, dof)\n",
    "    \n",
    "    # Convert p-value to significance in sigma\n",
    "    significance_sigma_t = norm.isf(p_value_t)  # isf = inverse survival function (1 - CDF)\n",
    "    significance_sigma_x = norm.isf(p_value_x)  # isf = inverse survival function (1 - CDF)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Tangential signal\")\n",
    "    print(f\"Chi-squared statistic: {chi2_stat_t:.3f}\")\n",
    "    print(f\"Degrees of freedom: {dof}\")\n",
    "    print(f\"p-value: {p_value_t:.4e}\")\n",
    "    print(f\"Detection significance: {significance_sigma_t:.2f} sigma\")\n",
    "    print(\"\\nCross signal\")\n",
    "    print(f\"Chi-squared statistic: {chi2_stat_x:.3f}\")\n",
    "    print(f\"Degrees of freedom: {dof}\")\n",
    "    print(f\"p-value: {p_value_x:.4e}\")\n",
    "    print(f\"Detection significance: {significance_sigma_x:.2f} sigma\")\n",
    "\n",
    "# get galaxy density plot from a GC Object\n",
    "NOBJ = int(1e8) # Number of randoms to Monte-Carlo sample over\n",
    "\n",
    "def gal_den_profile(gc_object, heal_mask):\n",
    "    \n",
    "    gal_density = []\n",
    "    gal_density_err = []\n",
    "    for i,rbin in enumerate(gc_object.profile):\n",
    "        Ngal = gc_object.profile[i]['n_src']\n",
    "        rmin = gc_object.profile[i]['radius_min']\n",
    "        rmax = gc_object.profile[i]['radius_max']\n",
    "\n",
    "        theta_min = cosmo.mpc2rad(rmin, 0.22)*180*60/np.pi # arcmin\n",
    "        theta_max = cosmo.mpc2rad(rmax, 0.22)*180*60/np.pi # arcmin\n",
    "\n",
    "        theta_deg_min = cosmo.mpc2rad(rmin, 0.22)*180/np.pi # degrees\n",
    "        theta_deg_max = cosmo.mpc2rad(rmax, 0.22)*180/np.pi # degrees\n",
    "\n",
    "        # calculate area with masked area removed\n",
    "        circ_min = hsp.Circle(ra=ra_bcg, dec=dec_bcg, radius=theta_deg_min, value=1)\n",
    "        circ_max = hsp.Circle(ra=ra_bcg, dec=dec_bcg, radius=theta_deg_max, value=1)\n",
    "\n",
    "        smap_min = circ_min.get_map(nside_coverage=32, nside_sparse=32768, dtype=np.int16)\n",
    "        smap_max = circ_max.get_map(nside_coverage=32, nside_sparse=32768, dtype=np.int16)\n",
    "        smap = smap_max.apply_mask(smap_min, in_place=False) # remove hsp pixels from inner circle\n",
    "        \n",
    "        ra_rand, dec_rand = hsp.make_uniform_randoms_fast(smap, NOBJ)\n",
    "        mask_rand = ~heal_mask['full_mask'].get_values_pos(ra_rand, dec_rand, lonlat=True)\n",
    "        prop_kept = np.count_nonzero(mask_rand)/NOBJ\n",
    "        \n",
    "        print(Ngal)\n",
    "        total_area = np.pi*(theta_max*theta_max - theta_min*theta_min) # sq arcmin\n",
    "        gal_density.append(Ngal/(prop_kept*total_area))\n",
    "        gal_density_err.append(np.sqrt(Ngal)/(prop_kept*total_area))\n",
    "\n",
    "    # get global number density\n",
    "    Ngal = np.sum(gc_object.profile['n_src'])\n",
    "    rmax = gc_object.profile[-1]['radius_max']\n",
    "\n",
    "    theta_max = cosmo.mpc2rad(rmax, 0.22)*180*60/np.pi # arcmin\n",
    "    theta_deg_max = cosmo.mpc2rad(rmax, 0.22)*180/np.pi # degrees\n",
    "\n",
    "    # calculate area with masked area removed\n",
    "    circ_max = hsp.Circle(ra=ra_bcg, dec=dec_bcg, radius=theta_deg_max, value=1)\n",
    "    smap = circ_max.get_map(nside_coverage=32, nside_sparse=32768, dtype=np.int16)\n",
    "    \n",
    "    ra_rand, dec_rand = hsp.make_uniform_randoms_fast(smap, NOBJ)\n",
    "    mask_rand = ~heal_mask['full_mask'].get_values_pos(ra_rand, dec_rand, lonlat=True)\n",
    "    prop_kept = np.count_nonzero(mask_rand)/NOBJ\n",
    "    \n",
    "    total_area = np.pi*(theta_max*theta_max) # sq arcmin\n",
    "    total_gal_density = Ngal/(prop_kept*total_area)\n",
    "    total_gal_density_err = np.sqrt(Ngal)/(prop_kept*total_area)\n",
    "    print(f\"Total galaxy density (per sq arcmin): {total_gal_density}, error: {total_gal_density_err}\")\n",
    "\n",
    "    return gc_object.profile['radius'], gal_density, gal_density_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99afac3-ef0c-4182-a354-ac0831da584e",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b0aa2-5d36-4a1e-b809-390b1f449386",
   "metadata": {},
   "source": [
    "Metadetect outputs tables for each patch. Read in each table and compile them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70703c-9206-4e9e-8824-be60be1e71a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasetRefs_shear = []\n",
    "overlap_patches_10463 = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "tract_patch_list = [] # only used for plotting distribution of input images\n",
    "\n",
    "for ref in butler.registry.queryDatasets('ShearObject', collections=collection):\n",
    "\n",
    "    # the only parts of these tracts within 0.5 radius overlap with already included patches\n",
    "    if ref.dataId['tract'] == 10704 or ref.dataId['tract'] == 10705:\n",
    "        continue\n",
    "\n",
    "    # these column of patches overlap with patches already in tract 10464\n",
    "    if ref.dataId['tract'] == 10463 and ref.dataId['patch'] in overlap_patches_10463:\n",
    "        continue\n",
    "    \n",
    "    datasetRefs_shear.append(butler.query_datasets('ShearObject', \n",
    "                                                     collections=collection,\n",
    "                                                     skymap = 'lsst_cells_v1',\n",
    "                                                     tract=ref.dataId['tract'],\n",
    "                                                     patch=ref.dataId['patch']))\n",
    "\n",
    "    tract_patch_list.append([ref.dataId['tract'], ref.dataId['patch']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99040123-8d3c-47f3-a89f-78214f60aedb",
   "metadata": {},
   "source": [
    "Combine the data from each patch into a single table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33151fd-dfd0-4b35-a572-2cb9bf86d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shear_table_list = []\n",
    "\n",
    "for i, ref in enumerate(datasetRefs_shear):\n",
    "    shear_data_patch = butler.get(ref[0])\n",
    "    shear_table_patch = shear_data_patch.to_pandas()\n",
    "    shear_table_list.append(shear_table_patch)\n",
    "\n",
    "shear_table = pd.concat(shear_table_list)\n",
    "\n",
    "# remove unused tables to clear up memory\n",
    "del shear_table_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f465de9-0989-4712-825c-3e675c86cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw catalogs if desired\n",
    "# if meas_type == 'wmom':\n",
    "#     shear_table_wl.to_pickle(\"./md-raw-wmom.pkl\")\n",
    "# elif meas_type == 'gauss':\n",
    "#     shear_table_wl.to_pickle(\"./md-raw-gauss.pkl\")\n",
    "# elif meas_type == 'pgauss':\n",
    "#     shear_table_wl.to_pickle(\"./md-raw-pgauss.pkl\")\n",
    "# else:\n",
    "#     print(\"Not an available measurement type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ad4f8-69c3-496b-a6c3-dc74fe54ac9c",
   "metadata": {},
   "source": [
    "Remove objects flagged by Metadetection - anything flagged should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d5e8d-9dd5-438a-b09f-18fd83d4e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many flagged objects are initially in catalog\n",
    "meta_filter = shear_table[f'{meas_type}_flags']==False\n",
    "meta_filter &= shear_table['psfrec_flags']==False\n",
    "meta_filter &= shear_table[f'{meas_type}_psf_flags']==False\n",
    "meta_filter &= shear_table[f'{meas_type}_obj_flags']==False\n",
    "meta_filter &= shear_table[f'{meas_type}_T_flags']==False\n",
    "meta_filter &= shear_table[f'{meas_type}_band_flux_flags_r']==False\n",
    "meta_filter &= shear_table[f'{meas_type}_band_flux_flags_i']==False\n",
    "\n",
    "print(\"Total number of objects from the raw catalog: \", len(shear_table))\n",
    "print(\"Total number of objects from the raw catalog in ns: \", len(shear_table[shear_table['shear_type']=='ns']))\n",
    "shear_table = shear_table[meta_filter]\n",
    "# print(\"Number of rows after removing metadetect flags: \", len(shear_table[meta_filter]))\n",
    "# print(\"Number of rows in ns after removing metadetect flags: \", len(shear_table[meta_filter][shear_table[meta_filter]['shear_type']=='ns']))\n",
    "print(\"Number of rows after removing metadetect flags: \", len(shear_table))\n",
    "print(\"Number of rows in ns after removing metadetect flags: \", len(shear_table[shear_table['shear_type']=='ns']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e099d091-f441-46c6-92f3-0933ee752d82",
   "metadata": {},
   "source": [
    "### Remove duplicate objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1aeae-3a35-4acc-adeb-66129f3be517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy table prior to duplicate removal for a later validation plot\n",
    "shear_table_dup = shear_table.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62455b27-1099-436e-bf54-ccfa9bda63e3",
   "metadata": {},
   "source": [
    "Remove duplicate objects from patch overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e190d2a7-f12b-463f-8e47-3b7ad5f2e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove objects in outer ring of cells in each patch since patch overlap is two cells\n",
    "# TO-DO: exempt rows that don't overlap with other patches, e.g. patches on the edge of the field\n",
    "shear_table = shear_table[shear_table['cell_x']!=0]\n",
    "shear_table = shear_table[shear_table['cell_x']!=21]\n",
    "shear_table = shear_table[shear_table['cell_y']!=0]\n",
    "shear_table = shear_table[shear_table['cell_y']!=21]\n",
    "print(\"Number of rows after removing most duplicate cells: \", len(shear_table))\n",
    "print(\"Number of rows after removing most duplicate cells in ns: \", len(shear_table[shear_table['shear_type']=='ns']))\n",
    "\n",
    "# some additional tract/patch overlap appears to have a 4 cell overlap\n",
    "filt1 = shear_table['tract'] == 10464\n",
    "filt1 &= shear_table['patch_x'] == 9\n",
    "filt1 &= shear_table['cell_x'] == 20\n",
    "shear_table = shear_table[np.invert(filt1)]\n",
    "\n",
    "filt2 = shear_table['tract'] == 10463\n",
    "filt2 &= shear_table['patch_x'] == 1\n",
    "filt2 &= shear_table['cell_x'] == 1\n",
    "shear_table = shear_table[np.invert(filt2)]\n",
    "\n",
    "print()\n",
    "print(\"Number of rows after removing patch overlap areas: \", len(shear_table))\n",
    "print(\"Number of rows after removing patch overlap areas in ns: \", len(shear_table[shear_table['shear_type']=='ns']))\n",
    "\n",
    "# remove overlapping rows due to patch overlap    \n",
    "print(\"Number of rows prior to removing duplicates: \", len(shear_table))\n",
    "shear_table = shear_table.drop_duplicates(subset=['shear_type', 'ra', 'dec']) # each object will potentially have several sheared images\n",
    "print(\"Number of rows after removing duplicates: \", len(shear_table))\n",
    "print(\"Number of rows after removing duplicates in ns: \", len(shear_table[shear_table['shear_type']=='ns']))\n",
    "\n",
    "# concating the per-patch catalogs together results in non-unique indices\n",
    "shear_table.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf741b0-d6dc-4e20-b554-ef83eeb66daf",
   "metadata": {},
   "source": [
    "Remove duplicate objects from cell overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a2d1b-1453-4352-96a8-441fccec90cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# is there a better way to do this? Probably\n",
    "dup_cell_ndx = []\n",
    "\n",
    "for i, tract_patch in enumerate(tract_patch_list):\n",
    "        \n",
    "    tract = tract_patch[0]\n",
    "    patch = tract_patch[1]\n",
    "\n",
    "    coadd = butler.get(\"deepCoaddCell\", \n",
    "                    tract=tract, \n",
    "                    patch=patch, \n",
    "                    band='i', \n",
    "                    skymap='lsst_cells_v1', \n",
    "                    collections=cell_collection)\n",
    "\n",
    "    shear_len_before = len(shear_table)\n",
    "\n",
    "    for cell_index in coadd.cells:\n",
    "        cell = coadd.cells[Index2D(x=cell_index.x, y=cell_index.y)]\n",
    "        cell_center = cell.inner.bbox.getCenter()\n",
    "\n",
    "        # find objects in this cell\n",
    "        filt_loc = shear_table['tract'] == tract\n",
    "        filt_loc &= shear_table['patch_y'] == (patch - (patch % 10)) // 10\n",
    "        filt_loc &= shear_table['patch_x'] == (patch % 10)\n",
    "        filt_loc &= shear_table['cell_x'] == cell_index.x\n",
    "        filt_loc &= shear_table['cell_y'] == cell_index.y\n",
    "\n",
    "        cell_objs = shear_table[filt_loc]\n",
    "\n",
    "        if len(cell_objs)==0:\n",
    "            continue\n",
    "            \n",
    "        # identify those objects that are beyond the inner cell region \n",
    "        # 75 pixels from the center in either dimension (inner cell length is 150 pixels)\n",
    "        outer_filt = cell_objs['col'] > (cell_center[0] + 75)\n",
    "        outer_filt |= cell_objs['col'] < (cell_center[0] - 75)\n",
    "        outer_filt |= cell_objs['row'] > (cell_center[1] + 75)\n",
    "        outer_filt |= cell_objs['row'] < (cell_center[1] - 75)\n",
    "\n",
    "        dup_cell_ndx.extend(cell_objs[outer_filt].index.to_list())\n",
    "\n",
    "    print(tract_patch)\n",
    "    del coadd\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dad471-8ed7-4df6-aac0-e3dbc7bad57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_cell_ndx = np.unique(dup_cell_ndx)\n",
    "shear_table.drop(dup_cell_ndx, inplace=True)\n",
    "\n",
    "print(\"Number of objects after duplicates removes: \", len(shear_table))\n",
    "print(\"Number of objects in ns after duplicates removes: \", len(shear_table[shear_table['shear_type']=='ns']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3b6eb3-a14f-4b89-a4b0-a38a9214fde6",
   "metadata": {},
   "source": [
    "### Add useful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d936a-90e3-4b6c-8eda-27cdf7e4dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new columns to convert nJy fluxes to AB magnitudes\n",
    "t1 = Table.from_pandas(shear_table)\n",
    "\n",
    "t1[f'{meas_type}_band_mag_g'] = (t1[f'{meas_type}_band_flux_g']*u.nJy).to(u.ABmag)\n",
    "t1[f'{meas_type}_band_mag_r'] = (t1[f'{meas_type}_band_flux_r']*u.nJy).to(u.ABmag)\n",
    "t1[f'{meas_type}_band_mag_i'] = (t1[f'{meas_type}_band_flux_i']*u.nJy).to(u.ABmag)\n",
    "t1[f'{meas_type}_color_mag_g-r'] = t1[f'{meas_type}_band_mag_g']-t1[f'{meas_type}_band_mag_r']\n",
    "t1[f'{meas_type}_color_mag_g-i'] = t1[f'{meas_type}_band_mag_g']-t1[f'{meas_type}_band_mag_i']\n",
    "t1[f'{meas_type}_color_mag_r-i'] = t1[f'{meas_type}_band_mag_r']-t1[f'{meas_type}_band_mag_i']\n",
    "\n",
    "shear_table = t1.to_pandas()\n",
    "\n",
    "# Add columns for distance from BCG\n",
    "c1 = SkyCoord(shear_table['ra'].values*u.deg, shear_table['dec'].values*u.deg)\n",
    "c2 = SkyCoord(ra_bcg*u.deg, dec_bcg*u.deg)\n",
    "sep = c1.separation(c2)\n",
    "\n",
    "shear_table['deg_sep'] = sep.value\n",
    "\n",
    "shear_table['mpc_sep'] = cosmo.eval_da(0.22) * shear_table['deg_sep'] * np.pi/180\n",
    "\n",
    "# uncertainties, flux errors are 1 standard deviation\n",
    "shear_table[f'{meas_type}_mag_g_err'] = (2.5 / np.log(10)) * (shear_table[f'{meas_type}_band_flux_err_g'] / shear_table[f'{meas_type}_band_flux_g'])\n",
    "shear_table[f'{meas_type}_mag_r_err'] = (2.5 / np.log(10)) * (shear_table[f'{meas_type}_band_flux_err_r'] / shear_table[f'{meas_type}_band_flux_r'])\n",
    "shear_table[f'{meas_type}_mag_i_err'] = (2.5 / np.log(10)) * (shear_table[f'{meas_type}_band_flux_err_i'] / shear_table[f'{meas_type}_band_flux_i'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a65d4f-02cf-447e-89d1-20eb294222ac",
   "metadata": {},
   "source": [
    "### Save / Read Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7bebf5-b76a-4316-bcd5-861e7e53c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save catalog so far\n",
    "# if meas_type == 'wmom':\n",
    "#     shear_table.to_pickle(\"./md-dup-wmom.pkl\")\n",
    "# elif meas_type == 'gauss':\n",
    "#     shear_table.to_pickle(\"./md-dup-gauss.pkl\")\n",
    "# elif meas_type == 'pgauss':\n",
    "#     shear_table.to_pickle(\"./md-dup-pgauss.pkl\")\n",
    "# else:\n",
    "#     print(\"Not an available measurement type\")\n",
    "\n",
    "# read in catalog to skip other steps\n",
    "if meas_type == 'wmom':\n",
    "    shear_table = pd.read_pickle(\"./md-dup-wmom.pkl\")\n",
    "elif meas_type == 'gauss':\n",
    "    shear_table = pd.read_pickle(\"./md-dup-gauss.pkl\")\n",
    "elif meas_type == 'pgauss':\n",
    "    shear_table = pd.read_pickle(\"./md-dup-pgauss.pkl\")\n",
    "else:\n",
    "    print(\"Not an available measurement type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f59aacf-ebb4-46e1-be49-34a12887092e",
   "metadata": {},
   "source": [
    "## Identify and remove cluster member galaxies (all r axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa9a42-aa8b-49d0-8d51-7dba8840c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate no shear catalog\n",
    "shear_table_ns = shear_table[shear_table['shear_type']=='ns']\n",
    "\n",
    "# pick plot parameters based on measurement type\n",
    "if meas_type == 'wmom':\n",
    "    g_line, r_line, i_line = 25.7, 25.4, 25.0\n",
    "    ymax = 50000\n",
    "elif meas_type == 'gauss':\n",
    "    g_line, r_line, i_line = 24.6, 24.2, 23.8\n",
    "    ymax = 50000\n",
    "elif meas_type == 'pgauss':\n",
    "    g_line, r_line, i_line = 24.8, 24.4, 24.0\n",
    "    ymax = 50000\n",
    "else:\n",
    "    print(\"Not an available measurement type\")\n",
    "\n",
    "# distribution of magnitudes prior to cuts\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\n",
    "ax[0].hist(shear_table_ns[f'{meas_type}_band_mag_g'], bins=75)\n",
    "ax[0].set_title(\"g-band\")\n",
    "ax[0].vlines(x=g_line, ymin=0, ymax=ymax, color='red')\n",
    "ax[1].hist(shear_table_ns[f'{meas_type}_band_mag_r'], bins=75)\n",
    "ax[1].set_title(\"r-band\")\n",
    "ax[1].vlines(x=r_line, ymin=0, ymax=ymax, color='red')\n",
    "ax[2].hist(shear_table_ns[f'{meas_type}_band_mag_i'], bins=75)\n",
    "ax[2].set_title(\"i-band\")\n",
    "ax[2].vlines(x=i_line, ymin=0, ymax=ymax, color='red')\n",
    "\n",
    "for ax in ax.reshape(-1):\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(\"AB Mag\")\n",
    "    ax.set_xlim(right=29)\n",
    "    ax.set_ylim(top=ymax)\n",
    "\n",
    "plt.savefig(f'image_outputs_{meas_type}/object-magnitudes.png', bbox_inches='tight')\n",
    "plt.suptitle(\"Object Magnitudes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a0514-394c-4d63-a4a7-6fe85a3b37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shear_table_wl = shear_table[shear_table['deg_sep'] < 0.5].copy() # catalog for WL measurements\n",
    "print(\"Number of rows after applying < 0.5 deg from center: \", len(shear_table_wl))\n",
    "print(\"Number of rows in ns after applying < 0.5 deg from center: \", len(shear_table_wl[shear_table_wl['shear_type']=='ns']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93403378-5f29-45f1-bccb-936518dbc89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting parameters\n",
    "point_size = 0.6\n",
    "point_alpha = 0.7\n",
    "\n",
    "mag_lim = 24\n",
    "bright_lim = 18\n",
    "\n",
    "# how many sigma to include in RS selection\n",
    "sigma = 1\n",
    "\n",
    "if meas_type == 'wmom':\n",
    "    # slope, upper range, lower range\n",
    "    rs_range = [(-0.09, 2.15, 1.85), # g-i\n",
    "                (-0.03, 0.67, 0.47), # r-i\n",
    "                (-0.07, 1.53, 1.37)] # g-r\n",
    "elif meas_type == 'gauss':\n",
    "    rs_range = [(-0.06, 2.05, 1.75),\n",
    "                (-0.03, 0.63, 0.50),\n",
    "                (-0.04, 1.43, 1.25)]\n",
    "elif meas_type == 'pgauss':\n",
    "    rs_range = [(-0.08, 2.05, 1.85),\n",
    "                (-0.025, 0.62, 0.5),\n",
    "                (-0.05, 1.45, 1.28)]\n",
    "else:\n",
    "    print(\"Not an available measurement type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9a7ff-36bd-4a32-8156-703ab78e51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RS_id(table, sigma, mag_lim, bright_lim, rs_range):\n",
    "\n",
    "    # ranges\n",
    "    gi_table_line_up = (table[f'{meas_type}_band_mag_r'] - 18) * (rs_range[0][0]) + rs_range[0][1]\n",
    "    ri_table_line_up = (table[f'{meas_type}_band_mag_r'] - 18) * (rs_range[1][0]) + rs_range[1][1]\n",
    "    gr_table_line_up = (table[f'{meas_type}_band_mag_r'] - 18) * (rs_range[2][0]) + rs_range[2][1]\n",
    "    \n",
    "    gi_table_line_down = (table[f'{meas_type}_band_mag_r'] - 18) * (rs_range[0][0]) + rs_range[0][2]\n",
    "    ri_table_line_down = (table[f'{meas_type}_band_mag_r'] - 18) * (rs_range[1][0]) + rs_range[1][2]\n",
    "    gr_table_line_down = (table[f'{meas_type}_band_mag_r'] - 18) * (rs_range[2][0]) + rs_range[2][2]\n",
    "    \n",
    "    gi_err = np.sqrt(table[f'{meas_type}_mag_g_err']**2 + table[f'{meas_type}_mag_i_err']**2)\n",
    "    ri_err = np.sqrt(table[f'{meas_type}_mag_r_err']**2 + table[f'{meas_type}_mag_i_err']**2)\n",
    "    gr_err = np.sqrt(table[f'{meas_type}_mag_g_err']**2 + table[f'{meas_type}_mag_r_err']**2)\n",
    "\n",
    "    gi_err_up = table[f'{meas_type}_color_mag_g-i'] + sigma * gi_err\n",
    "    gi_err_down = table[f'{meas_type}_color_mag_g-i'] - sigma * gi_err\n",
    "    ri_err_up = table[f'{meas_type}_color_mag_r-i'] + sigma * ri_err\n",
    "    ri_err_down = table[f'{meas_type}_color_mag_r-i'] - sigma * ri_err\n",
    "    gr_err_up = table[f'{meas_type}_color_mag_g-r'] + sigma * gr_err\n",
    "    gr_err_down = table[f'{meas_type}_color_mag_g-r'] - sigma * gr_err\n",
    "\n",
    "    '''\n",
    "    There are 4 cases that we want to consider for RS selection:\n",
    "    - Case 1: RS data without errors is within RS selection\n",
    "    - Case 2: Upper error bar end is within RS selection\n",
    "    - Case 3: Lower error bar end is within RS selection\n",
    "    - Case 4: Upper error bar is above RS selection\n",
    "                AND lower error bar is below RS selection\n",
    "\n",
    "    An object that falls within any of these cases should be selected.\n",
    "    '''\n",
    "\n",
    "    gi_redseq = np.logical_and.reduce((np.logical_or.reduce((\n",
    "                                            np.logical_and.reduce((\n",
    "                                                table[f'{meas_type}_color_mag_g-i'] < gi_table_line_up,\n",
    "                                                table[f'{meas_type}_color_mag_g-i'] > gi_table_line_down,)),\n",
    "                                            np.logical_and.reduce((\n",
    "                                                gi_err_up < gi_table_line_up,\n",
    "                                                gi_err_up > gi_table_line_down,)),\n",
    "                                            np.logical_and.reduce((\n",
    "                                                gi_err_down < gi_table_line_up,\n",
    "                                                gi_err_down > gi_table_line_down,)),\n",
    "                                            np.logical_and.reduce((\n",
    "                                                gi_err_up > gi_table_line_up,\n",
    "                                                gi_err_down < gi_table_line_down,)),\n",
    "                                       )),\n",
    "                                       table[f'{meas_type}_band_mag_r'] < mag_lim, \n",
    "                                       table[f'{meas_type}_band_mag_r'] > bright_lim))\n",
    "\n",
    "    ri_redseq = np.logical_and.reduce((np.logical_or.reduce((\n",
    "                                            np.logical_and.reduce((\n",
    "                                                table[f'{meas_type}_color_mag_r-i'] < ri_table_line_up,\n",
    "                                                table[f'{meas_type}_color_mag_r-i'] > ri_table_line_down,)),\n",
    "                                            np.logical_and.reduce((\n",
    "                                                ri_err_up < ri_table_line_up,\n",
    "                                                ri_err_up > ri_table_line_down,)),\n",
    "                                            np.logical_and.reduce((\n",
    "                                                ri_err_down < ri_table_line_up,\n",
    "                                                ri_err_down > ri_table_line_down,)),\n",
    "                                            np.logical_and.reduce((\n",
    "                                                ri_err_up > ri_table_line_up,\n",
    "                                                ri_err_down < ri_table_line_down,)),\n",
    "                                       )),\n",
    "                                       table[f'{meas_type}_band_mag_r'] < mag_lim, \n",
    "                                       table[f'{meas_type}_band_mag_r'] > bright_lim))\n",
    "    \n",
    "    gr_redseq = np.logical_and.reduce((np.logical_or.reduce((\n",
    "                                            np.logical_and.reduce((\n",
    "                                                table[f'{meas_type}_color_mag_g-r'] < gr_table_line_up,\n",
    "                                                table[f'{meas_type}_color_mag_g-r'] > gr_table_line_down,)),\n",
    "                                            np.logical_and.reduce((\n",
    "                                                gr_err_up < gr_table_line_up,\n",
    "                                                gr_err_up > gr_table_line_down,)),\n",
    "                                            np.logical_and.reduce((\n",
    "                                                gr_err_down < gr_table_line_up,\n",
    "                                                gr_err_down > gr_table_line_down,)),\n",
    "                                            np.logical_and.reduce((\n",
    "                                                gr_err_up > gr_table_line_up,\n",
    "                                                gr_err_down < gr_table_line_down,)),\n",
    "                                       )),\n",
    "                                       table[f'{meas_type}_band_mag_r'] < mag_lim, \n",
    "                                       table[f'{meas_type}_band_mag_r'] > bright_lim))\n",
    "    \n",
    "    all_redseq = np.logical_and.reduce((gi_redseq, ri_redseq, gr_redseq))\n",
    "\n",
    "    redeq_ind = [gi_redseq, ri_redseq, gr_redseq]\n",
    "\n",
    "    lines = [[gi_table_line_up, gi_table_line_down],\n",
    "             [ri_table_line_up, ri_table_line_down],\n",
    "             [gr_table_line_up, gr_table_line_down]]\n",
    "\n",
    "    return all_redseq, redeq_ind, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616464c8-2e6c-4e1e-b3e4-0d8aa42b8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single cell RS removal\n",
    "\n",
    "all_redseq, _, _ = RS_id(shear_table_wl, sigma, mag_lim, bright_lim, rs_range)\n",
    "\n",
    "# Filter out objects found in all_redseq\n",
    "shear_table_wl = shear_table_wl[~all_redseq]\n",
    "shear_table_wl_ns = shear_table_wl[shear_table_wl['shear_type']=='ns']\n",
    "\n",
    "print(\"Number of rows after 0.5 degree cut and RS cuts: \", len(shear_table_wl))\n",
    "print(\"Number of rows after 0.5 degree cut and RS cuts, ns only: \", len(shear_table_wl_ns))\n",
    "\n",
    "shear_table_rs_cuts = shear_table_wl.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbfc6fd-6ae7-4c46-875c-99dc114d48a3",
   "metadata": {},
   "source": [
    "### Visual Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7396bc4e-fbae-457c-b1b6-2a708179dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shear_table_wl_ns = shear_table_wl[shear_table_wl['shear_type'] == 'ns'].copy()\n",
    "shear_table_rs = shear_table_wl[shear_table_wl['deg_sep'] < 0.1].copy()\n",
    "shear_table_rs_ns = shear_table_rs[shear_table_rs['shear_type'] == 'ns']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4ec9e-e715-4f98-9ac0-b0e3cc78b525",
   "metadata": {},
   "source": [
    "#### Inner range of galaxies (< 0.1 Deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1b54b-785f-4849-a10b-e6538aae1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranges\n",
    "all_redseq, redseq_list, lines = RS_id(shear_table_rs_ns, sigma, mag_lim, bright_lim, rs_range)\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(19, 6))\n",
    "\n",
    "axes[0].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'], shear_table_rs_ns[f'{meas_type}_color_mag_g-i'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[0].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'][redseq_list[0]], \n",
    "           shear_table_rs_ns[f'{meas_type}_color_mag_g-i'][redseq_list[0]], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[0].set_ylabel('g-i')\n",
    "axes[0].set_xlabel('r')\n",
    "\n",
    "axes[0].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[0][0], color='r', linewidth=0.7)\n",
    "axes[0].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[0][1], color='r', linewidth=0.7)\n",
    "axes[0].set_ylim([-1,4])\n",
    "axes[0].set_xlim([17,27])\n",
    "\n",
    "axes[1].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'], shear_table_rs_ns[f'{meas_type}_color_mag_r-i'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[1].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'][redseq_list[1]], \n",
    "           shear_table_rs_ns[f'{meas_type}_color_mag_r-i'][redseq_list[1]], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[1].set_ylabel('r-i')\n",
    "axes[1].set_xlabel('r')\n",
    "\n",
    "axes[1].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[1][0], color='r', linewidth=0.7)\n",
    "axes[1].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[1][1], color='r', linewidth=0.7)\n",
    "axes[1].set_ylim([-1,2])\n",
    "axes[1].set_xlim([17,27])\n",
    "\n",
    "axes[2].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'], shear_table_rs_ns[f'{meas_type}_color_mag_g-r'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[2].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'][redseq_list[2]], \n",
    "           shear_table_rs_ns[f'{meas_type}_color_mag_g-r'][redseq_list[2]], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[2].set_ylabel('g-r')\n",
    "axes[2].set_xlabel('r')\n",
    "\n",
    "axes[2].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[2][0], color='r', linewidth=0.7)\n",
    "axes[2].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[2][1], color='r', linewidth=0.7)\n",
    "axes[2].set_ylim([-0.5,2])\n",
    "axes[2].set_xlim([17,27])\n",
    "\n",
    "plt.suptitle(\"Color-Magnitude < 0.1 deg\\nIndependent RS Cuts\")\n",
    "fig.savefig(f'image_outputs_{meas_type}/01-RS-indv_cuts.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ec2ae-14f4-4073-b9ea-a849873f6df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(19, 6))\n",
    "\n",
    "axes[0].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'], shear_table_rs_ns[f'{meas_type}_color_mag_g-i'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[0].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'][all_redseq], \n",
    "           shear_table_rs_ns[f'{meas_type}_color_mag_g-i'][all_redseq], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[0].set_ylabel('g-i')\n",
    "axes[0].set_xlabel('r')\n",
    "\n",
    "axes[0].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[0][0], color='r', linewidth=0.7)\n",
    "axes[0].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[0][1], color='r', linewidth=0.7)\n",
    "axes[0].set_ylim([-1,4])\n",
    "axes[0].set_xlim([17,27])\n",
    "\n",
    "axes[1].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'], shear_table_rs_ns[f'{meas_type}_color_mag_r-i'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[1].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'][all_redseq], \n",
    "           shear_table_rs_ns[f'{meas_type}_color_mag_r-i'][all_redseq], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[1].set_ylabel('r-i')\n",
    "axes[1].set_xlabel('r')\n",
    "\n",
    "axes[1].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[1][0], color='r', linewidth=0.7)\n",
    "axes[1].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[1][1], color='r', linewidth=0.7)\n",
    "axes[1].set_ylim([-1,2])\n",
    "axes[1].set_xlim([17,27])\n",
    "\n",
    "axes[2].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'], shear_table_rs_ns[f'{meas_type}_color_mag_g-r'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[2].scatter(shear_table_rs_ns[f'{meas_type}_band_mag_r'][all_redseq], \n",
    "           shear_table_rs_ns[f'{meas_type}_color_mag_g-r'][all_redseq], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[2].set_ylabel('g-r')\n",
    "axes[2].set_xlabel('r')\n",
    "\n",
    "axes[2].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[2][0], color='r', linewidth=0.7)\n",
    "axes[2].plot(shear_table_rs_ns[f'{meas_type}_band_mag_r'], lines[2][1], color='r', linewidth=0.7)\n",
    "axes[2].set_ylim([-0.5,2])\n",
    "axes[2].set_xlim([17,27])\n",
    "\n",
    "plt.suptitle(\"Color-Magnitude < 0.1 deg\\nCombined RS Cuts\")\n",
    "fig.savefig(f'image_outputs_{meas_type}/01-RS-all_cuts.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ea486-a0c3-4b08-9e74-e0dceeaac958",
   "metadata": {},
   "source": [
    "#### Most galaxies (< 0.5 Deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00c979-8dbe-4094-8e34-8491ba7bed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranges\n",
    "all_redseq, redseq_list, lines = RS_id(shear_table_wl_ns, sigma, mag_lim, bright_lim, rs_range)\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(19, 6))\n",
    "\n",
    "axes[0].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'], shear_table_wl_ns[f'{meas_type}_color_mag_g-i'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[0].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'][redseq_list[0]], \n",
    "           shear_table_wl_ns[f'{meas_type}_color_mag_g-i'][redseq_list[0]], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[0].set_ylabel('g-i')\n",
    "axes[0].set_xlabel('r')\n",
    "\n",
    "axes[0].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[0][0], color='r', linewidth=0.7)\n",
    "axes[0].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[0][1], color='r', linewidth=0.7)\n",
    "axes[0].set_ylim([-1,4])\n",
    "axes[0].set_xlim([17,27])\n",
    "\n",
    "axes[1].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'], shear_table_wl_ns[f'{meas_type}_color_mag_r-i'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[1].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'][redseq_list[1]], \n",
    "           shear_table_wl_ns[f'{meas_type}_color_mag_r-i'][redseq_list[1]], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[1].set_ylabel('r-i')\n",
    "axes[1].set_xlabel('r')\n",
    "\n",
    "axes[1].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[1][0], color='r', linewidth=0.7)\n",
    "axes[1].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[1][1], color='r', linewidth=0.7)\n",
    "axes[1].set_ylim([-1,2])\n",
    "axes[1].set_xlim([17,27])\n",
    "\n",
    "axes[2].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'], shear_table_wl_ns[f'{meas_type}_color_mag_g-r'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[2].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'][redseq_list[2]], \n",
    "           shear_table_wl_ns[f'{meas_type}_color_mag_g-r'][redseq_list[2]], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[2].set_ylabel('g-r')\n",
    "axes[2].set_xlabel('r')\n",
    "\n",
    "axes[2].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[2][0], color='r', linewidth=0.7)\n",
    "axes[2].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[2][1], color='r', linewidth=0.7)\n",
    "axes[2].set_ylim([-0.5,2])\n",
    "axes[2].set_xlim([17,27])\n",
    "\n",
    "plt.suptitle(\"Color-Magnitude < 0.5 deg\\nIndividual RS Cuts\")\n",
    "fig.savefig(f'image_outputs_{meas_type}/05-RS-indv_cuts.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea51b4f-ed61-48fc-aa7e-43d1b55ba1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(19, 6))\n",
    "\n",
    "axes[0].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'], shear_table_wl_ns[f'{meas_type}_color_mag_g-i'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[0].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'][all_redseq], \n",
    "           shear_table_wl_ns[f'{meas_type}_color_mag_g-i'][all_redseq], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[0].set_ylabel('g-i')\n",
    "axes[0].set_xlabel('r')\n",
    "\n",
    "axes[0].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[0][0], color='r', linewidth=0.7)\n",
    "axes[0].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[0][1], color='r', linewidth=0.7)\n",
    "axes[0].set_ylim([-1,4])\n",
    "axes[0].set_xlim([17,27])\n",
    "\n",
    "axes[1].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'], shear_table_wl_ns[f'{meas_type}_color_mag_r-i'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[1].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'][all_redseq], \n",
    "           shear_table_wl_ns[f'{meas_type}_color_mag_r-i'][all_redseq], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[1].set_ylabel('r-i')\n",
    "axes[1].set_xlabel('r')\n",
    "\n",
    "axes[1].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[1][0], color='r', linewidth=0.7)\n",
    "axes[1].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[1][1], color='r', linewidth=0.7)\n",
    "axes[1].set_ylim([-1,2])\n",
    "axes[1].set_xlim([17,27])\n",
    "\n",
    "axes[2].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'], shear_table_wl_ns[f'{meas_type}_color_mag_g-r'], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[2].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'][all_redseq], \n",
    "           shear_table_wl_ns[f'{meas_type}_color_mag_g-r'][all_redseq], \n",
    "           marker='.', s=point_size) #red sequence galaxies\n",
    "axes[2].set_ylabel('g-r')\n",
    "axes[2].set_xlabel('r')\n",
    "\n",
    "axes[2].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[2][0], color='r', linewidth=0.7)\n",
    "axes[2].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[2][1], color='r', linewidth=0.7)\n",
    "axes[2].set_ylim([-0.5,2])\n",
    "axes[2].set_xlim([17,27])\n",
    "\n",
    "plt.suptitle(\"Color-Magnitude < 0.5 deg\\nCombined RS Cuts\")\n",
    "fig.savefig(f'image_outputs_{meas_type}/05-RS-all_cuts.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ec72e-c5fd-4a2b-89d4-741f618e8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(19, 6))\n",
    "\n",
    "axes[0].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'][~all_redseq], shear_table_wl_ns[f'{meas_type}_color_mag_g-i'][~all_redseq], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[0].set_ylabel('g-i')\n",
    "axes[0].set_xlabel('r')\n",
    "\n",
    "axes[0].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[0][0], color='r', linewidth=0.7)\n",
    "axes[0].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[0][1], color='r', linewidth=0.7)\n",
    "axes[0].set_ylim([-1,4])\n",
    "axes[0].set_xlim([17,27])\n",
    "\n",
    "axes[1].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'][~all_redseq], shear_table_wl_ns[f'{meas_type}_color_mag_r-i'][~all_redseq], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[1].set_ylabel('r-i')\n",
    "axes[1].set_xlabel('r')\n",
    "\n",
    "axes[1].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[1][0], color='r', linewidth=0.7)\n",
    "axes[1].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[1][1], color='r', linewidth=0.7)\n",
    "axes[1].set_ylim([-1,2])\n",
    "axes[1].set_xlim([17,27])\n",
    "\n",
    "axes[2].scatter(shear_table_wl_ns[f'{meas_type}_band_mag_r'][~all_redseq], shear_table_wl_ns[f'{meas_type}_color_mag_g-r'][~all_redseq], \n",
    "           marker='.', s=point_size) # all galaxies  \n",
    "axes[2].set_ylabel('g-r')\n",
    "axes[2].set_xlabel('r')\n",
    "\n",
    "axes[2].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[2][0], color='r', linewidth=0.7)\n",
    "axes[2].plot(shear_table_wl_ns[f'{meas_type}_band_mag_r'], lines[2][1], color='r', linewidth=0.7)\n",
    "axes[2].set_ylim([-0.5,2])\n",
    "axes[2].set_xlim([17,27])\n",
    "\n",
    "plt.suptitle(\"Color-Magnitude < 0.5 deg\\nRS Removed\")\n",
    "fig.savefig(f'image_outputs_{meas_type}/05-RS-removed.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51394e4-4899-4b91-a043-9f5d58ae16a9",
   "metadata": {},
   "source": [
    "## Apply masks as done in mask technote\n",
    "\n",
    "For example notebook, see [here](https://github.com/lsst-sitcom/comcam_clusters/blob/main/A360_masking_example.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f7f24-7e2f-4646-9949-f19522b3be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_hsp = hsp.HealSparseMap.read('/home/b/bclevine/A360/A360_full_mask_hsp_128_131072.parquet')\n",
    "\n",
    "# mask = ~mask_hsp['full_mask'].get_values_pos(shear_table_wl['ra'], shear_table_wl['dec'], lonlat=True)\n",
    "star_mask = ~mask_hsp['bo'].get_values_pos(shear_table_wl['ra'], shear_table_wl['dec'], lonlat=True) # bright objects\n",
    "dust_mask = ~mask_hsp['sfd'].get_values_pos(shear_table_wl['ra'], shear_table_wl['dec'], lonlat=True) # masks from SFD dust map\n",
    "hand_mask = ~mask_hsp['hand'].get_values_pos(shear_table_wl['ra'], shear_table_wl['dec'], lonlat=True)  # masks done by hand, e.g. galactic cirrus\n",
    "exp_mask = ~mask_hsp['exp'].get_values_pos(shear_table_wl['ra'], shear_table_wl['dec'], lonlat=True) # edge / num exp mask\n",
    "\n",
    "mask = star_mask & dust_mask & hand_mask & exp_mask\n",
    "\n",
    "print(\"Number of rows in ns before mask applied: \", len(shear_table_wl[shear_table_wl['shear_type']=='ns']))\n",
    "shear_table_wl = shear_table_wl[mask]\n",
    "print(\"Number of rows in ns after mask applied : \", len(shear_table_wl[shear_table_wl['shear_type']=='ns']))\n",
    "\n",
    "shear_table_masked = shear_table_wl.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303c66e-6ac3-42af-8a71-02f16e1ffa35",
   "metadata": {},
   "source": [
    "## Quality cuts\n",
    "\n",
    "Some cuts based on [Yamamoto 2024](https://arxiv.org/abs/2501.05665) (such as T_ratio and color-color cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9930c-9609-418f-9c8b-b7b6fe3c38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store cut values in a dictionary\n",
    "if meas_type == 'wmom':\n",
    "    mag_i = 24.0\n",
    "    t_ratio = 1.05\n",
    "elif meas_type == 'gauss':\n",
    "    mag_i = 23.5\n",
    "    t_ratio = 0.2\n",
    "elif meas_type == 'pgauss':\n",
    "    mag_i = 23.75\n",
    "    t_ratio = 0.2\n",
    "else:\n",
    "    print(\"Not an available measurement type\")\n",
    "\n",
    "cut_dict = {'s2n' : 10,\n",
    "            'T' : 20,\n",
    "            'mfrac' : 0.1,\n",
    "            'color' : 5,\n",
    "            'bright' : 20,\n",
    "            'mag_i' : mag_i,\n",
    "            't_ratio' : t_ratio}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831bf04-80bf-4839-8261-100edd95822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rows_removed(og_table, meas_type, cut_dict, sigma):\n",
    "    total = len(og_table)\n",
    "\n",
    "    # create filter for star-galaxy cut\n",
    "    sg_cut = og_table[f'{meas_type}_T_ratio'] > cut_dict['t_ratio']\n",
    "    sg_cut &= (og_table[f'{meas_type}_T_ratio']-sigma*og_table[f'{meas_type}_T_err']) > cut_dict['t_ratio']\n",
    "    \n",
    "    print(f\"{meas_type}_T_ratio rows removed: \", total-len(og_table[sg_cut]), \"  (\", \\\n",
    "    (1 - len(og_table[sg_cut]) / total))\n",
    "    print(f\"{meas_type}_band_mag_i rows removed: \", total-len(og_table[og_table[f'{meas_type}_band_mag_i']<=cut_dict['mag_i']]), \"  (\", \\\n",
    "    (1 - len(og_table[og_table[f'{meas_type}_band_mag_i']<=cut_dict['mag_i']]) / total))\n",
    "    print(f\"{meas_type}_s2n rows removed: \", total-len(og_table[og_table[f'{meas_type}_s2n']>cut_dict['s2n']]), \"  (\", \\\n",
    "        (1 - len(og_table[og_table[f'{meas_type}_s2n']>cut_dict['s2n']]) / total))\n",
    "    print(f\"{meas_type}_T rows removed: \", total-len(og_table[og_table[f'{meas_type}_T']<cut_dict['T']]), \"  (\", \\\n",
    "        (1 - len(og_table[og_table[f'{meas_type}_T']<cut_dict['T']]) / total))\n",
    "    print(\"m_frac rows removed: \", total-len(og_table[og_table['mfrac']<cut_dict['mfrac']]), \"  (\", \\\n",
    "        (1 - len(og_table[og_table['mfrac']<cut_dict['mfrac']]) / total))\n",
    "    print(f\"{meas_type}_color_mag_g-r rows removed: \", total-len(og_table[(og_table[f'{meas_type}_color_mag_g-r']).abs()<cut_dict['color']]), \"  (\", \\\n",
    "        (1 - len(og_table[(og_table[f'{meas_type}_color_mag_g-r']).abs()<cut_dict['color']]) / total))\n",
    "    print(f\"{meas_type}_color_mag_r-i rows removed: \", total-len(og_table[(og_table[f'{meas_type}_color_mag_r-i']).abs()<cut_dict['color']]), \"  (\", \\\n",
    "        (1 - len(og_table[(og_table[f'{meas_type}_color_mag_r-i']).abs()<cut_dict['color']]) / total))\n",
    "    print(f\"{meas_type}_color_mag_g-i rows removed: \", total-len(og_table[(og_table[f'{meas_type}_color_mag_g-i']).abs()<cut_dict['color']]), \"  (\", \\\n",
    "        (1 - len(og_table[(og_table[f'{meas_type}_color_mag_g-i']).abs()<cut_dict['color']]) / total))\n",
    "    print(f\"{meas_type}_band_mag_i<20 rows removed: \", total-len(og_table[og_table[f'{meas_type}_band_mag_i']>cut_dict['bright']]), \"  (\", \\\n",
    "        (1 - len(og_table[og_table[f'{meas_type}_band_mag_i']>cut_dict['bright']]) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926165d1-bd4c-4b5c-bf34-14733c7dc62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuts determined mainly from Yamamoto but also additional analyses here\n",
    "sigma = 0\n",
    "\n",
    "final_cuts = shear_table_wl[f'{meas_type}_s2n']>cut_dict['s2n']\n",
    "final_cuts &= shear_table_wl[f'{meas_type}_T']<cut_dict['T']\n",
    "final_cuts &= shear_table_wl['mfrac']<cut_dict['mfrac']\n",
    "final_cuts &= (shear_table_wl[f'{meas_type}_color_mag_g-r']).abs()<cut_dict['color']\n",
    "final_cuts &= (shear_table_wl[f'{meas_type}_color_mag_r-i']).abs()<cut_dict['color']\n",
    "final_cuts &= (shear_table_wl[f'{meas_type}_color_mag_g-i']).abs()<cut_dict['color']\n",
    "final_cuts &= shear_table_wl[f'{meas_type}_band_mag_i']>cut_dict['bright']\n",
    "# final_cuts &= (shear_table[f'{meas_type}_T_ratio'] - sigma*(shear_table[f'{meas_type}_T_err']/shear_table[f'{meas_type}_psf_T'])>cut_dict['t_ratio'])\n",
    "final_cuts &= (shear_table[f'{meas_type}_T_ratio']>cut_dict['t_ratio'])\n",
    "final_cuts &= shear_table_wl[f'{meas_type}_band_mag_i']<=cut_dict['mag_i']\n",
    "    \n",
    "print_rows_removed(shear_table_wl, meas_type, cut_dict, sigma)\n",
    "\n",
    "shear_table_wl = shear_table_wl[final_cuts]\n",
    "shear_table_wl_ns = shear_table_wl[shear_table_wl['shear_type']=='ns']\n",
    "\n",
    "print()\n",
    "print(\"Number of rows after applying quality cuts: \", len(shear_table_wl))\n",
    "print(\"Number of rows in ns after applying quality cuts: \", len(shear_table_wl_ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959416b6-3190-4e82-b25c-000e6542e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final sample\n",
    "if meas_type == 'wmom':\n",
    "    shear_table_wl.to_pickle(\"./md-wl-wmom.pkl\")\n",
    "\n",
    "    # also save as fits file\n",
    "    shear_table_wl_table = Table.from_pandas(shear_table_wl)\n",
    "    shear_table_wl_table.write('./md-wl-wmom.fits', overwrite=True)\n",
    "elif meas_type == 'gauss':\n",
    "    shear_table_wl.to_pickle(\"./md-wl-gauss.pkl\")\n",
    "\n",
    "    shear_table_wl_table = Table.from_pandas(shear_table_wl)\n",
    "    shear_table_wl_table.write('./md-wl-gauss.fits', overwrite=True)\n",
    "elif meas_type == 'pgauss':\n",
    "    shear_table_wl.to_pickle(\"./md-wl-pgauss.pkl\")\n",
    "\n",
    "    shear_table_wl_table = Table.from_pandas(shear_table_wl)\n",
    "    shear_table_wl_table.write('./md-wl-pgauss.fits', overwrite=True)\n",
    "else:\n",
    "    print(\"Not an available measurement type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1beb4-cda4-482a-ad85-49ac07e13312",
   "metadata": {},
   "source": [
    "## Check shear types for each object\n",
    "\n",
    "Each object is detected and measured separately for each sheared/unsheared image. The catalogs will not necessarily be the same but should be close in number of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b525c8b7-1f25-4f58-85fb-fdfadb803903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split catalog by shear type\n",
    "shear_table_wl_ns = shear_table_wl[shear_table_wl['shear_type']=='ns']\n",
    "shear_table_wl_1p = shear_table_wl[shear_table_wl['shear_type']=='1p']\n",
    "shear_table_wl_1m = shear_table_wl[shear_table_wl['shear_type']=='1m']\n",
    "shear_table_wl_2p = shear_table_wl[shear_table_wl['shear_type']=='2p']\n",
    "shear_table_wl_2m = shear_table_wl[shear_table_wl['shear_type']=='2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6684d-f79e-402f-998d-f1b62a4301ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of shear type 'ns': \", len(shear_table_wl_ns))\n",
    "print(\"Number of shear type '1p': \", len(shear_table_wl_1p))\n",
    "print(\"Number of shear type '1m': \", len(shear_table_wl_1m))\n",
    "print(\"Number of shear type '2p': \", len(shear_table_wl_2p))\n",
    "print(\"Number of shear type '2m': \", len(shear_table_wl_2m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab38fd72-1df5-4e9c-9b4b-dbb39ede3768",
   "metadata": {},
   "source": [
    "# Match to photo-z catalog\n",
    "\n",
    "Methods from https://github.com/lsst-sitcom/comcam_clusters/blob/main/ACO360_WL_Anacal_PZmatching.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a3c7f0-55db-4494-bb63-93142947b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running at USDF RSP?\n",
    "pz_sv38_point = '/sdf/data/rubin/shared/pz/projects/dp1/data/gold_baseline/dp1_sv38/dp1_v29.0.0_gold_Rubin_SV_38_7_photoz_cat.parquet'\n",
    "pz_sv38_pdf_dir = '/sdf/data/rubin/shared/pz/projects/dp1/data/gold_baseline/dp1_sv38'\n",
    "\n",
    "pz_algs = ['bpz', 'tpz', 'fzboost', 'knn', 'gpz', 'dnf', 'lephare', 'cmnn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6b7ef-8a6e-479d-85f8-c29eb2b8ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = list('griz')\n",
    "# bands = list('gri')\n",
    "cmodel_bands = [b+suffix for b in bands for suffix in ['_cModelFlux', '_cModelFluxErr', '_cModel_flag']]\n",
    "gaap_bands = [b+suffix for b in bands for suffix in ['_gaap1p0Flux', '_gaap1p0FluxErr',  '_gaapFlux_flag']]\n",
    "psf_bands = [b+suffix for b in bands for suffix in ['_psfFlux', '_psfFluxErr',  '_psfFlux_flag']]\n",
    "extended_bands = [b+'_extendedness' for b in bands]\n",
    "\n",
    "object_req_cols = ['coord_ra', 'coord_dec', 'refExtendedness', 'objectId',\n",
    "            'parentObjectId', 'shape_xx', 'shape_xy', 'shape_yy', 'refBand', 'x', 'y',\n",
    "            'patch', 'tract', 'i_ixxPSF', 'i_iyyPSF', 'i_ixyPSF', 'i_iPSF_flag',\n",
    "            'i_hsmShapeRegauss_e1', 'i_hsmShapeRegauss_e2',\n",
    "            'i_hsmShapeRegauss_flag', 'i_hsmShapeRegauss_sigma', 'i_blendedness' ] + cmodel_bands + gaap_bands + extended_bands + psf_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0fdfc-4d0d-4a2b-8a23-1acc220a529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pz_photomdata(tracts=[10463, 10464],\n",
    "                       ddir='/sdf/data/rubin/shared/pz/data/dp1_v29.0.0_gold/',\n",
    "                       suffix = 'pq',\n",
    "                       columns=object_req_cols\n",
    "                      ):\n",
    "    object_cat = []\n",
    "\n",
    "    for tract in tracts:\n",
    "        tract_data = pd.read_parquet(ddir+str(tract)+'/object.' + suffix)\n",
    "        relevant_data = Table.from_pandas(tract_data[columns])\n",
    "        object_cat.append(relevant_data)\n",
    "\n",
    "    preclean_table = vstack(object_cat)\n",
    "\n",
    "    for b in list('griz'):\n",
    "        preclean_table[f'{b}_cModel_mag'] = u.nJy.to(u.ABmag, preclean_table[f'{b}_cModelFlux'])\n",
    "        preclean_table[f'{b}_gaap_mag'] = u.nJy.to(u.ABmag, preclean_table[f'{b}_gaap1p0Flux'])\n",
    "\n",
    "    preclean_table['gi'] = preclean_table['g_gaap_mag'] - preclean_table['i_gaap_mag']\n",
    "    preclean_table['gr'] = preclean_table['g_gaap_mag'] - preclean_table['r_gaap_mag']\n",
    "    preclean_table['ri'] = preclean_table['r_gaap_mag'] - preclean_table['i_gaap_mag']\n",
    "\n",
    "    c1 = SkyCoord(preclean_table['coord_ra']*u.deg, preclean_table['coord_dec']*u.deg)\n",
    "    c2 = SkyCoord(ra_bcg*u.deg, dec_bcg*u.deg)\n",
    "    sep = c1.separation(c2)\n",
    "    preclean_table['sep'] = sep.deg\n",
    "    return preclean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541f52f-07ee-4d38-9f74-943ea51572bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_data = load_pz_photomdata()\n",
    "pz_coords = np.vstack((pz_data['coord_ra'], pz_data['coord_dec'])).T\n",
    "\n",
    "pz_tree = KDTree(pz_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1fe7ed-8ecb-4972-b6d2-80ba5e6bc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_bpz = qp.read(f'{pz_sv38_pdf_dir}/output_estimate_bpz.hdf5') # for individial p(z)\n",
    "pz_point = pd.read_parquet(pz_sv38_point) # for point estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19094831-1603-49bd-a863-f5f2e5bc9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_pz_all(pz_points, indices):\n",
    "    \n",
    "    filts = []\n",
    "\n",
    "    pz_algs_reduced = ['bpz', 'tpz', 'fzboost', 'knn']\n",
    "    for alg in pz_algs:\n",
    "        if alg=='knn':\n",
    "            filt = pz_points.iloc[indices][f\"{alg}_z_median\"].values\n",
    "            filts.append(filt)\n",
    "            continue\n",
    "            \n",
    "        filt = pz_points.iloc[indices][f\"{alg}_z_mean\"].values\n",
    "        filts.append(filt)\n",
    "\n",
    "    # calculate the mean value across each pz alg type\n",
    "    mean_filt = np.mean(filts, axis=0)\n",
    "\n",
    "    return mean_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81a49f-40cb-430a-8c58-a12acdb3c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_pz(pz_points, indices, alg):\n",
    "    \n",
    "    filt = 0\n",
    "    pz_algs_reduced = ['bpz', 'tpz', 'fzboost', 'knn']\n",
    "    \n",
    "    if alg=='knn':\n",
    "        filt = pz_points.iloc[indices][f\"{alg}_z_median\"].values\n",
    "    else:\n",
    "        filt = pz_points.iloc[indices][f\"{alg}_z_mean\"].values\n",
    "\n",
    "    return filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7129ece2-183f-4163-8ef0-5838733ad305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdfs(algo_type, filt, pz_dir, weights=None):\n",
    "    '''\n",
    "    This function will take the individual photo-z object PDFs and\n",
    "    stack them to create an N(z). The filter provided will filter\n",
    "    to keep only the matched objects.\n",
    "    '''\n",
    "    xs = np.linspace(0, 3, 301)\n",
    "    pdfs = qp.read(f'{pz_dir}/output_estimate_{algo_type}.hdf5')\n",
    "    pdf_plot = pdfs[filt].pdf(xs)\n",
    "    if weights is None:\n",
    "        stacked_plot = np.sum(pdf_plot, axis=0)\n",
    "        normalized_plot = stacked_plot / len(filt)\n",
    "    else:\n",
    "        stacked_plot = np.dot(weights, pdf_plot)\n",
    "        normalized_plot = stacked_plot / np.sum(weights)\n",
    "        \n",
    "    # stacked_plot_all = np.sum(pdf_plot, axis=0)\n",
    "    # normalized_plot_all = stacked_plot_all / len(pdf_plot)\n",
    "\n",
    "    return normalized_plot, pdf_plot, xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f53f72-6d6a-491e-9973-fbcec1136b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shear_catalogs = [shear_table_wl_ns, shear_table_wl_1p, shear_table_wl_1m, shear_table_wl_2p, shear_table_wl_2m]\n",
    "dists_catalogs = []\n",
    "shear_pz_catalogs = []\n",
    "# initialize those only needed for NS catalog\n",
    "goodmatch_filt = 0\n",
    "ns_ndxs = 0\n",
    "pdf = 0\n",
    "\n",
    "pz_alg = 'dnf'\n",
    "point_est = 'mean'\n",
    "\n",
    "for i, catalog in enumerate(shear_catalogs):\n",
    "\n",
    "    catalog_og_len = len(catalog)\n",
    "    \n",
    "    meta_coords = np.vstack((catalog['ra'], catalog['dec'])).T\n",
    "    meta_tree = KDTree(meta_coords)\n",
    "\n",
    "    # ndxs are the indices of pz_coords during pz_tree intialization\n",
    "    dists, ndxs =  pz_tree.query(meta_coords, k=2) \n",
    "\n",
    "    goodmatch_filt_temp = dists[:,0] < 1/3600\n",
    "    \n",
    "    if i == 0:\n",
    "        goodmatch_filt = goodmatch_filt_temp\n",
    "        ns_ndxs = ndxs\n",
    "        pdf_filt = ndxs[goodmatch_filt_temp,0]\n",
    "\n",
    "        # generate a stacked N(z)\n",
    "        pdf, _, xs = get_pdfs(pz_alg, pdf_filt, pz_dir = pz_sv38_pdf_dir, weights=None)\n",
    "\n",
    "    # calculate a per-object photo-z point estimate from the available PDFs\n",
    "\n",
    "    # cut objects that are measured to be in front of the cluster\n",
    "    catalog_cut = catalog[goodmatch_filt_temp].copy()\n",
    "\n",
    "    if pz_alg == 'pz_all':\n",
    "        catalog_cut[f'{pz_alg}_mean'] = get_mean_pz_all(pz_point, ndxs[goodmatch_filt_temp,0])\n",
    "    else:\n",
    "        catalog_cut[f'{pz_alg}_mean'] = get_mean_pz(pz_point, ndxs[goodmatch_filt_temp,0], pz_alg)\n",
    "        \n",
    "    catalog_cut = catalog_cut[catalog_cut[f'{pz_alg}_mean']>0.37] # cut based off of STICOMTN-163\n",
    "\n",
    "    print(f\"Num metadetection: {catalog_og_len}. Num matches: {np.sum(goodmatch_filt_temp)}. Num final: {len(catalog_cut)}\")\n",
    "    \n",
    "    shear_pz_catalogs.append(catalog_cut)\n",
    "    dists_catalogs.append(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0440ebd6-fc94-4310-8d7b-8441bede854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DNF stacked N(z)\n",
    "# np.save(f'./metadetect_{meas_type}_{pz_alg}_nz', pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f8050-fc98-4d67-8945-fe23f6612048",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.array([beta_s_mean, beta_s_square_mean])\n",
    "np.save(f'./profile_metadetect_{meas_type}_beta_betas', betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5aa9d-7574-424a-a1a7-47d998bb2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 4))\n",
    "\n",
    "pz_algs = ['DNF']\n",
    "xs = np.linspace(0, 3, 301)\n",
    "for i, alg in enumerate(pz_algs):\n",
    "    ax.plot(xs, pdf, label=pz_algs[i])\n",
    "\n",
    "ax.legend(frameon=False)\n",
    "ax.set_xlim(0, 2)\n",
    "ax.set_xlabel(\"Redshift\")\n",
    "ax.set_ylabel(\"Normalized Counts\")\n",
    "ax.axvline(0.22, ls='--', color='r', alpha=0.25)\n",
    "ax.axvline(0.37, ls='--', color='k', alpha=0.25)\n",
    "ax.set_title(\"Weighted $N(z)$\")\n",
    "# ax.set_title(\"N(z) with $z \\\\geq 0.37$ and $\\\\sigma_z \\\\leq 0.25$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4aa7ed-fefe-4b56-93a0-fe8fac48e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pz_catalog_wl_list = []\n",
    "\n",
    "# for catalog in shear_pz_catalogs:\n",
    "#     pz_catalog_wl_list.append(catalog)\n",
    "    \n",
    "# pz_catalog_wl = pd.concat(pz_catalog_wl_list)\n",
    "# pz_catalog_wl.reset_index(inplace=True)\n",
    "\n",
    "# print(len(pz_catalog_wl))\n",
    "\n",
    "# pz_catalog_wl_table = Table.from_pandas(pz_catalog_wl)\n",
    "# pz_catalog_wl_table.write('./md-pz-gauss.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515628d-a465-4aff-821d-7faa63e44df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# logbins = np.geomspace(1e-5, 50, 51)\n",
    "\n",
    "# fig, axes = plt.subplots(2,3, figsize=(16,10), sharex=True, sharey=True)\n",
    "# # plt.subplots_adjust(wspace=0, hspace=0)\n",
    " \n",
    "# axes[0][0].hist(dists_catalogs[0][:,0] * 3600, bins=logbins, histtype='step', label='Nearest')\n",
    "# axes[0][0].hist(dists_catalogs[0][:,1] * 3600, bins=logbins, histtype='step', label='2nd Nearest')\n",
    "# axes[0][0].set_title(\"NS Catalog\")\n",
    "# axes[0][0].set_ylabel(\"counts\")\n",
    "\n",
    "# axes[0][1].hist(dists_catalogs[1][:,0] * 3600, bins=logbins, histtype='step', label='Nearest')\n",
    "# axes[0][1].hist(dists_catalogs[1][:,1] * 3600, bins=logbins, histtype='step', label='2nd Nearest')\n",
    "# axes[0][1].set_title(\"1P Catalog\")\n",
    "\n",
    "# axes[0][2].hist(dists_catalogs[2][:,0] * 3600, bins=logbins, histtype='step', label='Nearest')\n",
    "# axes[0][2].hist(dists_catalogs[2][:,1] * 3600, bins=logbins, histtype='step', label='2nd Nearest')\n",
    "# axes[0][2].set_title(\"1M Catalog\")\n",
    "\n",
    "# # leave [1][0] axes blank\n",
    "# axes[1][0].set_xlabel(\"Arcseconds\")\n",
    "# axes[1][0].set_ylabel(\"counts\")\n",
    "\n",
    "# axes[1][1].hist(dists_catalogs[3][:,0] * 3600, bins=logbins, histtype='step', label='Nearest')\n",
    "# axes[1][1].hist(dists_catalogs[3][:,1] * 3600, bins=logbins, histtype='step', label='2nd Nearest')\n",
    "# axes[1][1].set_title(\"2P Catalog\")\n",
    "# axes[1][1].set_xlabel(\"Arcseconds\")\n",
    "\n",
    "# axes[1][2].hist(dists_catalogs[4][:,0] * 3600, bins=logbins, histtype='step', label='Nearest')\n",
    "# axes[1][2].hist(dists_catalogs[4][:,1] * 3600, bins=logbins, histtype='step', label='2nd Nearest')\n",
    "# axes[1][2].set_title(\"2M Catalog\")\n",
    "# axes[1][2].set_xlabel(\"Arcseconds\")\n",
    "\n",
    "# for ax in axes.reshape(-1):\n",
    "#     ax.semilogx()\n",
    "#     ax.semilogy()\n",
    "\n",
    "# plt.suptitle(\"Distance to Nearest PZ Match\", size=15, y=0.95)\n",
    "# # plt.savefig(f'image_outputs_{meas_type}/object-distribution-before-after.png', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e55a87-c9b3-4885-b627-f740fd5ac411",
   "metadata": {},
   "source": [
    "# Looking at shear outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266e3a4-8dc0-4073-888d-db12d72ccea3",
   "metadata": {},
   "source": [
    "## Determining tangential & cross shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d558315-1921-41f9-9413-f1ab6b5092d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shear_diff = 0.02\n",
    "\n",
    "# bins_mpc = clmm.make_bins(0.5,6,nbins=6, method='evenlog10width')\n",
    "bins_mpc = clmm.make_bins((0.5/h), (3.2/(h*(1+0.22))), nbins=5, method='evenlog10width')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638d2cf-9a6a-4e05-9378-e61705fc2a75",
   "metadata": {},
   "source": [
    "### Global R with Beta's from Photo-z's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ffb5cb-e774-4492-981e-f567b0d655c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_mean = shear_table_wl_1p[f'{meas_type}_g_1'].mean()\n",
    "m1_mean = shear_table_wl_1m[f'{meas_type}_g_1'].mean()\n",
    "p2_mean = shear_table_wl_2p[f'{meas_type}_g_2'].mean()\n",
    "m2_mean = shear_table_wl_2m[f'{meas_type}_g_2'].mean()\n",
    "\n",
    "r_matrix = [[0, 0],[0, 0]]\n",
    "\n",
    "r_matrix[0][0] = (p1_mean - m1_mean) / shear_diff\n",
    "# r_matrix[0][1] = (p2_mean - m2_mean) / shear_diff # ignore?\n",
    "# r_matrix[1][0] = (p1_mean - m1_mean) / shear_diff\n",
    "r_matrix[1][1] = (p2_mean - m2_mean) / shear_diff\n",
    "\n",
    "r_matrix_inv = inv(r_matrix)\n",
    "\n",
    "# calculate R error\n",
    "p1_err = np.std(shear_table_wl_1p[f'{meas_type}_g_1']) / np.sqrt(len(shear_table_wl_1p[f'{meas_type}_g_1']))\n",
    "m1_err = np.std(shear_table_wl_1m[f'{meas_type}_g_1']) / np.sqrt(len(shear_table_wl_1m[f'{meas_type}_g_1']))\n",
    "p2_err = np.std(shear_table_wl_2p[f'{meas_type}_g_2']) / np.sqrt(len(shear_table_wl_2p[f'{meas_type}_g_2']))\n",
    "m2_err = np.std(shear_table_wl_2m[f'{meas_type}_g_2']) / np.sqrt(len(shear_table_wl_2m[f'{meas_type}_g_2']))\n",
    "\n",
    "r11_err = np.sqrt(p1_err**2 + m1_err**2)\n",
    "r22_err = np.sqrt(p2_err**2 + m2_err**2)\n",
    "\n",
    "print(\"R11, R22: \", r_matrix[0][0], r_matrix[1][1])\n",
    "print(\"R11_err, R22_err: \", r11_err, r22_err)\n",
    "print(\"Difference of R11 and R22: \", np.abs(r_matrix[0][0]-r_matrix[1][1]))\n",
    "\n",
    "# apply R to each g1/g2 pair\n",
    "g1_cal, g2_cal = r_matrix_inv.dot([shear_table_wl_ns[f'{meas_type}_g_1'], shear_table_wl_ns[f'{meas_type}_g_2']])\n",
    "g_cal = np.sqrt(g1_cal*g1_cal + g2_cal*g2_cal)\n",
    "\n",
    "# get shape uncertainties from covariance matrix\n",
    "g1_err = np.sqrt(shear_table_wl_ns[f'{meas_type}_g_cov_11'])\n",
    "g2_err = np.sqrt(shear_table_wl_ns[f'{meas_type}_g_cov_22'])\n",
    "g_err = (1/g_cal)*np.sqrt(g1_cal**2 * g1_err**2 + g2_cal**2 * g2_err**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88dd3a6-081a-400e-bab8-162678229a9b",
   "metadata": {},
   "source": [
    "#### GC Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1429410-1702-44e5-9a5a-53802a6b51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = 'celestial'\n",
    "\n",
    "galcat = GCData(meta={\"coordinate_system\": coord})\n",
    "galcat['ra'] = shear_table_wl_ns['ra']\n",
    "galcat['dec'] = shear_table_wl_ns['dec']\n",
    "galcat['e1'] = g1_cal\n",
    "galcat['e2'] = -g2_cal\n",
    "galcat['e_err'] = g_err\n",
    "galcat['id'] = np.arange(len(shear_table_wl_ns))\n",
    "galcat['z'] = np.zeros(len(shear_table_wl_ns))\n",
    "    \n",
    "cluster_id = \"Abell 360\"\n",
    "gc_object_beta = clmm.GalaxyCluster(cluster_id, ra_bcg, dec_bcg, 0.22, galcat)\n",
    "\n",
    "gc_object_beta.compute_tangential_and_cross_components(add=True)\n",
    "\n",
    "# gc_object_beta.galcat['w_ls'] = gc_object_beta.compute_galaxy_weights(\n",
    "#         shape_component1=\"e1\",\n",
    "#         shape_component2=\"e2\",\n",
    "#         use_shape_error=True,\n",
    "#         shape_component1_err=\"e_err\",\n",
    "#         shape_component2_err=\"e_err\",\n",
    "#         use_shape_noise=True,\n",
    "#         weight_name=\"w_ls\",\n",
    "#         cosmo=cosmo,\n",
    "#         add=True,\n",
    "#     )\n",
    "\n",
    "gc_object_beta.make_radial_profile(bins=bins_mpc, bin_units='Mpc', add=True, cosmo=cosmo,\n",
    "                               overwrite=True, use_weights=False, gal_ids_in_bins=False)\n",
    "\n",
    "gc_object_beta.save(f'./profile_metadetect_{meas_type}_beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc6a06-6d3d-41ee-8768-4efe83c8642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "moo = clmm.Modeling(massdef=\"critical\", delta_mdef=500, halo_profile_model=\"nfw\")\n",
    "\n",
    "moo.set_cosmo(cosmo)\n",
    "moo.set_concentration(3.5)\n",
    "# moo.set_mass(4.e14)\n",
    "moo.set_mass(6.e14)\n",
    "\n",
    "# z_cl = gc_object_beta.z\n",
    "z_cl = 0.22\n",
    "z_inf = 1000\n",
    "\n",
    "pz_estimate = shear_pz_catalogs[0][f'{pz_alg}_{point_est}'][shear_pz_catalogs[0][f'{pz_alg}_{point_est}']>0.37]\n",
    "\n",
    "# Compute first beta (e.g. eq(6) of WtGIII paper)\n",
    "beta_s_mean = clmm.utils.compute_beta_s_mean_from_weights(\n",
    "    pz_estimate,\n",
    "    z_cl,\n",
    "    z_inf,\n",
    "    cosmo,\n",
    "    shape_weights=None,\n",
    "    # shape_weights = galcat['w_ls'],\n",
    ")\n",
    "\n",
    "beta_s_square_mean = clmm.utils.compute_beta_s_square_mean_from_weights(\n",
    "    pz_estimate,\n",
    "    z_cl,\n",
    "    z_inf,\n",
    "    cosmo,\n",
    "    shape_weights=None,\n",
    "    # shape_weights = galcat['w_ls'],\n",
    ")\n",
    "\n",
    "rproj = np.logspace(np.log10(0.1),np.log10(7.), 100)\n",
    "\n",
    "gt_z = moo.eval_reduced_tangential_shear(\n",
    "    rproj, z_cl, [beta_s_mean, beta_s_square_mean], z_src_info=\"beta\", approx=\"order2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a18d6-6358-489e-ba49-15045580cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.array([beta_s_mean, beta_s_square_mean])\n",
    "np.save(f'./profile_metadetect_{meas_type}_beta_betas', betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d2c08-f3f8-4ae2-80b5-58b00426bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7,5))\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    'font.size': 14,\n",
    "    'axes.labelsize': 14,\n",
    "    'axes.titlesize': 14,\n",
    "    'xtick.labelsize': 14,\n",
    "    'ytick.labelsize': 14,\n",
    "    'legend.fontsize': 14\n",
    "})\n",
    "\n",
    "ax.errorbar(gc_object_beta.profile['radius'], gc_object_beta.profile['gt'], gc_object_beta.profile['gt_err'], \n",
    "             ls='', marker='.', label='tangential')\n",
    "ax.errorbar(gc_object_beta.profile['radius']*1.02, gc_object_beta.profile['gx'], gc_object_beta.profile['gx_err'], \n",
    "             ls='', marker='.', label='cross')\n",
    "ax.plot(rproj, gt_z, label=r'NFW, $M_{500c}=6 \\times 10^{14}$ M$_\\odot$, c=3.5, n(z)=Source dist.', ls=':')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.axhline(0.0, color='k', ls=':')\n",
    "ax.set_ylim([-0.06,0.11])\n",
    "ax.set_xlim([0.7,4.5])\n",
    "# ax.set_xlim([0.5,4.5])\n",
    "ax.set_xlabel('R [Mpc]')\n",
    "#plt.xlabel('separation [deg]')\n",
    "ax.set_ylabel('reduced shear')\n",
    "ax.legend(loc=1, fontsize=11)\n",
    "# ax.set_title(\"Chi-shapes with photo-z\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'image_outputs_{meas_type}/shear_profile_beta.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ae98af-90e9-4c26-8a5a-68169b316033",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_sig(gc_object_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed3b941-d3c3-4970-99bb-ec929a6c36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_rad, wl_den, wl_den_err = gal_den_profile(gc_object_beta, mask_hsp)\n",
    "\n",
    "plt.errorbar(wl_rad, wl_den, wl_den_err, ls='', marker='.')\n",
    "plt.xscale('log')\n",
    "plt.ylabel(r'$n_{\\rm gal}$ [arcmin$^{-2}$]')\n",
    "plt.xlabel(r'$R$ [Mpc]')\n",
    "plt.savefig(f'image_outputs_{meas_type}/gal_den_profile.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72002a-ab1c-4dc3-89c2-341dcc27fab9",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6623f65b-1525-4e4d-903b-a8239dbb4bb7",
   "metadata": {},
   "source": [
    "## Plot `T_ratio` vs S/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb5083-c8b7-47b0-8950-4598d7cb8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1, figsize=(7,6))\n",
    "\n",
    "shear_table_rs_cuts_ns = shear_table_rs_cuts[shear_table_rs_cuts['shear_type']=='ns']\n",
    "\n",
    "axes.scatter(np.log10(shear_table_rs_cuts_ns[f'{meas_type}_s2n']), shear_table_rs_cuts_ns[f'{meas_type}_T_ratio'], \n",
    "           marker='.', s=3, alpha=point_alpha, label=\"All\")\n",
    "axes.scatter(np.log10(shear_table_wl_ns[f'{meas_type}_s2n']), shear_table_wl_ns[f'{meas_type}_T_ratio'], \n",
    "           marker='.', s=3, alpha=point_alpha, label='Remaining')\n",
    "axes.set_xlabel('$log_{10}$(S/N)')\n",
    "axes.set_ylabel(f'{meas_type}_T_ratio')\n",
    "axes.hlines(cut_dict['t_ratio'], 0.5, 5, color='red', label=f'{cut_dict['t_ratio']} limit')\n",
    "\n",
    "if meas_type == 'gauss':\n",
    "    axes.set_ylim(-0.2, 2)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'image_outputs_{meas_type}/obj_T_vs_s2n.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75431384-7be7-4531-ba8b-956ab638f02f",
   "metadata": {},
   "source": [
    "## Plot object density as a function of every cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f12cba-04ac-4747-8612-453419e6c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_density = shear_table_rs_cuts.copy()\n",
    "obj_density = obj_density[obj_density['shear_type']=='ns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bbe213-4f4a-4b06-a9ca-af0238f5ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(19,6), sharex=True, sharey=True)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "axes[0].scatter(shear_table_dup['ra'][shear_table_dup['shear_type']=='ns'], shear_table_dup['dec'][shear_table_dup['shear_type']=='ns'], marker='.', s=0.1, alpha=0.6) \n",
    "axes[0].set_title(\"No cuts\")\n",
    "axes[0].set_xlabel(\"ra\")\n",
    "axes[0].set_ylabel(\"dec\")\n",
    "axes[0].invert_xaxis()\n",
    "\n",
    "axes[1].scatter(obj_density['ra'], obj_density['dec'], marker='.', s=0.1, alpha=0.6) \n",
    "axes[1].set_title(\"Duplicate and Red Sequence Cuts\")\n",
    "axes[1].set_xlabel(\"ra\")\n",
    "axes[1].invert_xaxis()\n",
    "\n",
    "axes[2].scatter(shear_table_wl_ns['ra'], shear_table_wl_ns['dec'], marker='.', s=0.1, alpha=0.6) \n",
    "axes[2].set_title(\"All cuts\")\n",
    "axes[2].set_xlabel(\"ra\")\n",
    "axes[2].set_xlim(ra_bcg-0.7, ra_bcg+0.7)\n",
    "axes[2].set_ylim(dec_bcg-0.7, dec_bcg+0.7)\n",
    "axes[2].invert_xaxis()\n",
    "\n",
    "for ax in axes.reshape(-1):\n",
    "    ax.scatter([ra_bcg], [dec_bcg], marker='+', s=100, color='orange')\n",
    "    # ax.set_xlim(37.8, 38.0)\n",
    "    # ax.set_ylim(6.9, 7.1)\n",
    "\n",
    "plt.suptitle(\"Object Distribution\", size=16, y=0.98)\n",
    "plt.savefig(f'image_outputs_{meas_type}/object-distribution-before-after.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81198332-3283-4a33-a443-6ba404de7f63",
   "metadata": {},
   "source": [
    "## Plot distribution of cell properties in A360 region\n",
    "\n",
    "Each run of the `get_cell_inputs` function should only take 3-4 minutes. If it's longer, try again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ef35f-fd35-410e-a3b7-d711edd7dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.sphgeom import Box, HealpixPixelization\n",
    "import healpy as hp\n",
    "from hpgeom import hpgeom\n",
    "import skyproj\n",
    "\n",
    "# create and configure stats control object as seen in assemble_cell_coadd task\n",
    "statsCtrl = afwMath.StatisticsControl()\n",
    "statsCtrl.setAndMask(afwImage.Mask.getPlaneBitMask((\"BAD\", \"NO_DATA\", \"SAT\"))) # use default PlaneBitMasks from task\n",
    "statsCtrl.setNanSafe(True)\n",
    "\n",
    "# define healpix parameters\n",
    "nside_coverage = 2**8\n",
    "nside_sparse = 2**14\n",
    "\n",
    "pixelization = HealpixPixelization(hp.nside2order(nside_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf91068-62db-47dc-8613-0f83e86f330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method find the pixel indices that overlap the sky projection of the cell area\n",
    "def get_cell_pixels(cell, wcs):\n",
    "    cell_bbox = cell.inner.bbox\n",
    "    begin_coord = wcs.pixelToSky(cell_bbox.beginX, cell_bbox.beginY)\n",
    "    end_coord = wcs.pixelToSky(cell_bbox.endX, cell_bbox.endY)\n",
    "    \n",
    "    if begin_coord.getRa() < end_coord.getRa():\n",
    "        ra1 = begin_coord.getRa().asDegrees()\n",
    "        ra2 = end_coord.getRa().asDegrees()\n",
    "    else:\n",
    "        ra1 = end_coord.getRa().asDegrees()\n",
    "        ra2 = begin_coord.getRa().asDegrees()\n",
    "    \n",
    "    if begin_coord.getDec() < end_coord.getDec():\n",
    "        dec1 = begin_coord.getDec().asDegrees()\n",
    "        dec2 = end_coord.getDec().asDegrees()\n",
    "    else:\n",
    "        dec1 = end_coord.getDec().asDegrees()\n",
    "        dec2 = begin_coord.getDec().asDegrees()\n",
    "\n",
    "    indices = hpgeom.query_box(nside=nside_sparse, a0=ra1, a1=ra2, b0=dec1, b1=dec2)\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463cddb1-c613-465f-a8b2-bb89bc2efb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return PSF e magnitude of the cell\n",
    "def get_psf_e(cell, wcs):\n",
    "    # get psf image of cell\n",
    "    psf_im = cell.psf_image\n",
    "    \n",
    "    psf_kernel = afwMath.FixedKernel(psf_im)\n",
    "    psf = meas.KernelPsf(psf_kernel)\n",
    "    shape = psf.computeShape(psf_im.getBBox().getCenter())\n",
    "    \n",
    "    trace_radius = shape.getTraceRadius()\n",
    "    i_xx, i_yy, i_xy = shape.getIxx(), shape.getIyy(), shape.getIxy()\n",
    "    \n",
    "    q = Quadrupole(i_xx, i_yy, i_xy)\n",
    "    s = SeparableDistortionTraceRadius(q)\n",
    "    \n",
    "    e1, e2 = s.getE1(), s.getE2()\n",
    "    e = np.sqrt(e1**2 + e2**2)\n",
    "    \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc2a63-dcde-458e-83a6-1a31ca325428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the limiting PSF magnitude of each pixel, given the cell object and statistics settings\n",
    "def get_mag_lim(cell, statsCtrl, zp=31.4, num_sigma=5):\n",
    "    \n",
    "    # get psf area of cell\n",
    "    psf_im = cell.psf_image.array\n",
    "    numer = np.square(np.sum(psf_im))\n",
    "    # numer = 1 # I've seen this as well, but said to be prone to changing if stamp size changes\n",
    "    denom = np.sum(np.square(psf_im))\n",
    "    psf_area = numer/denom\n",
    "\n",
    "    # get total cell weight\n",
    "    accTask = AssembleCellCoaddTask()\n",
    "    mask_im = cell.inner.asMaskedImage()\n",
    "    computed_weight = accTask._compute_weight(mask_im, statsCtrl)\n",
    "    # the computed weight will be the same value for each pixel\n",
    "    total_weight = computed_weight * mask_im.getDimensions()[0] * mask_im.getDimensions()[1]\n",
    "    \n",
    "    maglim = zp-2.5*np.log10(num_sigma*np.sqrt(psf_area/total_weight))\n",
    "    \n",
    "    return maglim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb948c9-1b27-4a37-90b9-9b031c717214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_inputs(cell_collection, tract_patch_list, band):\n",
    "\n",
    "    cell_df = pd.DataFrame()\n",
    "    cell_ra = []\n",
    "    cell_dec = []\n",
    "    pixel_indices = []\n",
    "    inputs_list = []\n",
    "    mag_lim_list = []\n",
    "    psf_e_list = []\n",
    "\n",
    "    segs = [] # collection of lines to plot patch outlines\n",
    "\n",
    "    for tract, patch in tract_patch_list:\n",
    "    \n",
    "        coadd = butler.get('deepCoaddCell', \n",
    "                         collections = cell_collection, \n",
    "                         instrument = 'LSSTComCam', \n",
    "                         skymap = 'lsst_cells_v1', \n",
    "                         tract = tract, \n",
    "                         patch = patch,\n",
    "                         band = band,)\n",
    "        # define a wcs from the given coadd\n",
    "        wcs = coadd.wcs\n",
    "\n",
    "        # get coadd outline\n",
    "        coadd_corners = coadd.inner_bbox.getCorners()\n",
    "    \n",
    "        for index, corner in enumerate(coadd_corners):\n",
    "            corner_coord_start = wcs.pixelToSky(corner.getX(), corner.getY())\n",
    "            if index < 3:\n",
    "                corner_coord_end = wcs.pixelToSky(coadd_corners[index+1].getX(), coadd_corners[index+1].getY())\n",
    "            else:\n",
    "                corner_coord_end = wcs.pixelToSky(coadd_corners[0].getX(), coadd_corners[0].getY())\n",
    "    \n",
    "            start_ra = corner_coord_start[0].asDegrees()\n",
    "            start_dec = corner_coord_start[1].asDegrees()\n",
    "    \n",
    "            end_ra = corner_coord_end[0].asDegrees()\n",
    "            end_dec = corner_coord_end[1].asDegrees()\n",
    "    \n",
    "            segs.append(((start_ra, start_dec), (end_ra, end_dec)))\n",
    "        \n",
    "        cell_list = list(coadd.cells.keys()) # skips indices that are empty\n",
    "\n",
    "        # for each cell in cell_list:\n",
    "        for index, cell_index in enumerate(cell_list):\n",
    "    \n",
    "            cell = coadd.cells[cell_index]\n",
    "    \n",
    "            # get cell coordinates for removing duplicates\n",
    "            cell_center = cell.inner.bbox.getCenter()\n",
    "            cell_center_coord = wcs.pixelToSky(cell_center)\n",
    "            cell_ra.append(cell_center_coord.getRa().asDegrees())\n",
    "            cell_dec.append(cell_center_coord.getDec().asDegrees())\n",
    "        \n",
    "            pixel_indices.append(get_cell_pixels(cell, wcs))\n",
    "    \n",
    "            inputs_list.append(cell.visit_count)\n",
    "            mag_lim_list.append(get_mag_lim(cell, statsCtrl))\n",
    "            psf_e_list.append(get_psf_e(cell, wcs))\n",
    "    \n",
    "        del coadd\n",
    "        gc.collect()\n",
    "\n",
    "    cell_df[\"ra\"] = cell_ra\n",
    "    cell_df[\"dec\"] = cell_dec\n",
    "    cell_df[\"pixels\"] = pixel_indices\n",
    "    cell_df[\"inputs\"] = inputs_list\n",
    "    cell_df[\"mag_lim\"] = mag_lim_list\n",
    "    cell_df[\"psf_e\"] = psf_e_list\n",
    "\n",
    "    return cell_df, segs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836d8003-b637-4ee5-8c18-90faf907072c",
   "metadata": {},
   "source": [
    "#### g-band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600e4cd-0935-42cb-a1db-7c5b9942e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df_g, segs_g = get_cell_inputs(cell_collection, tract_patch_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555a95f-2e16-4e3a-a867-fe4b74e7d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate cells from overlapping patches\n",
    "cell_df_g = cell_df_g.drop_duplicates(subset=['ra', 'dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8834490-aade-4e86-a0e9-e0b365693c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_df_g = cell_df_g.explode('pixels').reset_index(drop=True)\n",
    "pixel_df_g = pixel_df_g.drop_duplicates(subset=[\"pixels\"]) \n",
    "pixel_df_g = pixel_df_g.dropna(subset=['pixels'])\n",
    "\n",
    "pixels_g = pixel_df_g[\"pixels\"].to_numpy()\n",
    "pixel_input_g = pixel_df_g[\"inputs\"].to_numpy()\n",
    "pixel_mag_lim_g = pixel_df_g[\"mag_lim\"].to_numpy()\n",
    "pixel_psf_e_g = pixel_df_g[\"psf_e\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a9364-d99e-4c6f-849d-0bc17e2f54c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsp_map_input_g = hsp.HealSparseMap.make_empty(nside_coverage, nside_sparse, np.int64)\n",
    "hsp_map_input_g.update_values_pix(np.array(pixels_g, dtype=np.int64), np.array(pixel_input_g))\n",
    "\n",
    "hsp_map_mag_lim_g = hsp.HealSparseMap.make_empty(nside_coverage, nside_sparse, np.float64)\n",
    "hsp_map_mag_lim_g.update_values_pix(np.array(pixels_g, dtype=np.int64), np.array(pixel_mag_lim_g))\n",
    "\n",
    "hsp_map_psf_e_g = hsp.HealSparseMap.make_empty(nside_coverage, nside_sparse, np.float64)\n",
    "hsp_map_psf_e_g.update_values_pix(np.array(pixels_g, dtype=np.int64), np.array(pixel_psf_e_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b56ad3-3277-455d-bc39-5fd36aef967b",
   "metadata": {},
   "source": [
    "#### r-band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c66f9a-e8c6-49c2-9f96-2efedaf051b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df_r, segs_r = get_cell_inputs(cell_collection, tract_patch_list, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0aeb3c-b03a-4d15-9411-11c6de67fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate cells from overlapping patches\n",
    "cell_df_r = cell_df_r.drop_duplicates(subset=['ra', 'dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a0f44-a8a8-476d-9d3f-1ded64229024",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_df_r = cell_df_r.explode('pixels').reset_index(drop=True)\n",
    "pixel_df_r = pixel_df_r.drop_duplicates(subset=[\"pixels\"]) \n",
    "pixel_df_r = pixel_df_r.dropna(subset=['pixels'])\n",
    "\n",
    "pixels_r = pixel_df_r[\"pixels\"].to_numpy()\n",
    "pixel_input_r = pixel_df_r[\"inputs\"].to_numpy()\n",
    "pixel_mag_lim_r = pixel_df_r[\"mag_lim\"].to_numpy()\n",
    "pixel_psf_e_r = pixel_df_r[\"psf_e\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e3365-ea3b-4563-acf3-0b2400c628aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsp_map_input_r = hsp.HealSparseMap.make_empty(nside_coverage, nside_sparse, np.int64)\n",
    "hsp_map_input_r.update_values_pix(np.array(pixels_r, dtype=np.int64), np.array(pixel_input_r))\n",
    "\n",
    "hsp_map_mag_lim_r = hsp.HealSparseMap.make_empty(nside_coverage, nside_sparse, np.float64)\n",
    "hsp_map_mag_lim_r.update_values_pix(np.array(pixels_r, dtype=np.int64), np.array(pixel_mag_lim_r))\n",
    "\n",
    "hsp_map_psf_e_r = hsp.HealSparseMap.make_empty(nside_coverage, nside_sparse, np.float64)\n",
    "hsp_map_psf_e_r.update_values_pix(np.array(pixels_r, dtype=np.int64), np.array(pixel_psf_e_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d9620-0023-4d60-a641-e458969d350e",
   "metadata": {},
   "source": [
    "#### i-band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fbfa1e-bab7-4ad6-8775-732ff9e838bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df_i, segs_i = get_cell_inputs(cell_collection, tract_patch_list, 'i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be29066-3747-446a-adc9-95335d9e8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate cells from overlapping patches\n",
    "cell_df_i = cell_df_i.drop_duplicates(subset=['ra', 'dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a7855-9e7e-42d9-9a9e-aac981f0f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_df_i = cell_df_i.explode('pixels').reset_index(drop=True)\n",
    "pixel_df_i = pixel_df_i.drop_duplicates(subset=[\"pixels\"]) \n",
    "pixel_df_i = pixel_df_i.dropna(subset=['pixels'])\n",
    "\n",
    "pixels_i = pixel_df_i[\"pixels\"].to_numpy()\n",
    "pixel_input_i = pixel_df_i[\"inputs\"].to_numpy()\n",
    "pixel_mag_lim_i = pixel_df_i[\"mag_lim\"].to_numpy()\n",
    "pixel_psf_e_i = pixel_df_i[\"psf_e\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134dd2f-f0eb-4cc1-ae03-778992e27f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsp_map_input_i = hsp.HealSparseMap.make_empty(nside_coverage, nside_sparse, np.int64)\n",
    "hsp_map_input_i.update_values_pix(np.array(pixels_i, dtype=np.int64), np.array(pixel_input_i))\n",
    "\n",
    "hsp_map_mag_lim_i = hsp.HealSparseMap.make_empty(nside_coverage, nside_sparse, np.float64)\n",
    "hsp_map_mag_lim_i.update_values_pix(np.array(pixels_i, dtype=np.int64), np.array(pixel_mag_lim_i))\n",
    "\n",
    "hsp_map_psf_e_i = hsp.HealSparseMap.make_empty(nside_coverage, nside_sparse, np.float64)\n",
    "hsp_map_psf_e_i.update_values_pix(np.array(pixels_i, dtype=np.int64), np.array(pixel_psf_e_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c11d07-a324-4f25-8741-492790cf06a4",
   "metadata": {},
   "source": [
    "#### Input Distribution Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8c1ade-3280-4d7d-92c9-6c190ca95196",
   "metadata": {},
   "source": [
    "The three missing patches were due to pipeline failures, though are not included within the 0.5 degree radius of the BCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5b7dd-a56c-4f22-9735-5c68b4655a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(18, 5.3))\n",
    "sp_g = skyproj.GnomonicSkyproj(ax=ax[0], lon_0=37.862, lat_0=6.98, min_lon_ticklabel_delta=0.2)\n",
    "sp_g.draw_hspmap(hsp_map_input_g, vmin=1, vmax=pixel_input_i.max())\n",
    "sp_g.ax.circle(ra_bcg, dec_bcg, 0.5, color='cyan')\n",
    "sp_g.ax.circle(ra_bcg, dec_bcg, 0.3, color='darkorange')\n",
    "sp_g.ax.set_xlabel(\"RA (deg)\", fontsize=10,)\n",
    "sp_g.ax.set_ylabel(\"DEC (deg)\", fontsize=10,)\n",
    "sp_g.draw_colorbar(shrink=0.8, label='Number of input warps per cell')\n",
    "sp_g.ax.set_title(\"g-band\", pad=25)\n",
    "for seg in segs_g:\n",
    "    sp_g.ax.plot([seg[0][0], seg[1][0]], [seg[0][1], seg[1][1]], 'r-', alpha=0.6)\n",
    "\n",
    "sp_r = skyproj.GnomonicSkyproj(ax=ax[1], lon_0=37.862, lat_0=6.98, min_lon_ticklabel_delta=0.2)\n",
    "sp_r.draw_hspmap(hsp_map_input_r, vmin=1, vmax=pixel_input_i.max())\n",
    "sp_r.ax.circle(ra_bcg, dec_bcg, 0.5, color='cyan')\n",
    "sp_r.ax.circle(ra_bcg, dec_bcg, 0.3, color='darkorange')\n",
    "sp_r.ax.set_xlabel(\"RA (deg)\", fontsize=10,)\n",
    "sp_r.ax.set_ylabel(\"DEC (deg)\", fontsize=10,)\n",
    "sp_r.draw_colorbar(shrink=0.8, label='Number of input warps per cell')\n",
    "sp_r.ax.set_title(\"r-band\", pad=25)\n",
    "for seg in segs_r:\n",
    "    sp_r.ax.plot([seg[0][0], seg[1][0]], [seg[0][1], seg[1][1]], 'r-', alpha=0.6)\n",
    "    \n",
    "sp_i = skyproj.GnomonicSkyproj(ax=ax[2], lon_0=37.862, lat_0=6.98, min_lon_ticklabel_delta=0.2)\n",
    "sp_i.draw_hspmap(hsp_map_input_i, vmin=1, vmax=pixel_input_i.max())\n",
    "sp_i.ax.circle(ra_bcg, dec_bcg, 0.5, color='cyan')\n",
    "sp_i.ax.circle(ra_bcg, dec_bcg, 0.3, color='darkorange')\n",
    "sp_i.ax.set_xlabel(\"RA (deg)\", fontsize=10,)\n",
    "sp_i.ax.set_ylabel(\"DEC (deg)\", fontsize=10,)\n",
    "sp_i.draw_colorbar(shrink=0.8, label='Number of input warps per cell')\n",
    "sp_i.ax.set_title(\"i-band\", pad=25)\n",
    "for seg in segs_i:\n",
    "    sp_i.ax.plot([seg[0][0], seg[1][0]], [seg[0][1], seg[1][1]], 'r-', alpha=0.6)\n",
    "\n",
    "plt.suptitle(\"Input Image Distribution of the A360 Region\", size=15)\n",
    "\n",
    "plt.savefig(f'image_outputs_{meas_type}/3_band_image_distribution.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20fc279-b002-4734-a488-bd7cae618833",
   "metadata": {},
   "source": [
    "#### Limiting Magnitude Distribution Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9e7b8-2f4b-4627-90b3-cbcdf86efd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(19.5, 5.5))\n",
    "sp_g = skyproj.GnomonicSkyproj(ax=ax[0], lon_0=37.862, lat_0=6.98, min_lon_ticklabel_delta=0.2)\n",
    "sp_g.draw_hspmap(hsp_map_mag_lim_g)\n",
    "sp_g.ax.circle(ra_bcg, dec_bcg, 0.5, color='cyan')\n",
    "sp_g.ax.set_xlabel(\"RA (deg)\", fontsize=10,)\n",
    "sp_g.ax.set_ylabel(\"DEC (deg)\", fontsize=10,)\n",
    "sp_g.draw_colorbar(shrink=0.9, label='5-sigma Limiting Magnitude')\n",
    "sp_g.ax.set_title(\"g-band\", pad=25)\n",
    "for seg in segs_g:\n",
    "    sp_g.ax.plot([seg[0][0], seg[1][0]], [seg[0][1], seg[1][1]], 'r-', alpha=0.6)\n",
    "\n",
    "sp_r = skyproj.GnomonicSkyproj(ax=ax[1], lon_0=37.862, lat_0=6.98, min_lon_ticklabel_delta=0.2)\n",
    "sp_r.draw_hspmap(hsp_map_mag_lim_r)\n",
    "sp_r.ax.circle(ra_bcg, dec_bcg, 0.5, color='cyan')\n",
    "sp_r.ax.set_xlabel(\"RA (deg)\", fontsize=10,)\n",
    "sp_r.ax.set_ylabel(\"DEC (deg)\", fontsize=10,)\n",
    "sp_r.draw_colorbar(shrink=0.9, label='5-sigma Limiting Magnitude')\n",
    "sp_r.ax.set_title(\"r-band\", pad=25)\n",
    "for seg in segs_r:\n",
    "    sp_r.ax.plot([seg[0][0], seg[1][0]], [seg[0][1], seg[1][1]], 'r-', alpha=0.6)\n",
    "    \n",
    "sp_i = skyproj.GnomonicSkyproj(ax=ax[2], lon_0=37.862, lat_0=6.98, min_lon_ticklabel_delta=0.2)\n",
    "sp_i.draw_hspmap(hsp_map_mag_lim_i)\n",
    "sp_i.ax.circle(ra_bcg, dec_bcg, 0.5, color='cyan')\n",
    "sp_i.ax.set_xlabel(\"RA (deg)\", fontsize=10,)\n",
    "sp_i.ax.set_ylabel(\"DEC (deg)\", fontsize=10,)\n",
    "sp_i.draw_colorbar(shrink=0.9, label='5-sigma Limiting Magnitude')\n",
    "sp_i.ax.set_title(\"i-band\", pad=25)\n",
    "for seg in segs_i:\n",
    "    sp_i.ax.plot([seg[0][0], seg[1][0]], [seg[0][1], seg[1][1]], 'r-', alpha=0.6)\n",
    "\n",
    "plt.suptitle(\"5-sigma Limiting Magnitude Distribution of the A360 Region\", size=15)\n",
    "\n",
    "plt.savefig(f'image_outputs_{meas_type}/3_band_mag_lim_distribution.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d072adb-36a6-4802-b64f-8f39153b9a46",
   "metadata": {},
   "source": [
    "These plots should be taken with a grain of salt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1f4d12-df51-46ba-bb8c-38969ff1747e",
   "metadata": {},
   "source": [
    "#### PSF Ellipticity Distribution Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7add9b09-c642-4d70-bc18-64ba8c6b753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean PSF ellipticies for each band\n",
    "print(\"Mean PSF ellipticity in g-band: \", pixel_psf_e_g.mean())\n",
    "print(\"Mean PSF ellipticity in r-band: \", pixel_psf_e_r.mean())\n",
    "print(\"Mean PSF ellipticity in i-band: \", pixel_psf_e_i.mean())\n",
    "print()\n",
    "# median PSF ellipticies for each band\n",
    "print(\"Median PSF ellipticity in g-band: \", np.median(pixel_psf_e_g))\n",
    "print(\"Median PSF ellipticity in r-band: \", np.median(pixel_psf_e_r))\n",
    "print(\"Median PSF ellipticity in i-band: \", np.median(pixel_psf_e_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87101407-2787-4a21-bb6e-645055f2ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minimum / maximum PSF ellipticities for a consistent colorbar\n",
    "print(pixel_psf_e_g.min())\n",
    "print(pixel_psf_e_r.min())\n",
    "print(pixel_psf_e_i.min())\n",
    "\n",
    "print(pixel_psf_e_g.max())\n",
    "print(pixel_psf_e_r.max())\n",
    "print(pixel_psf_e_i.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe6f72d-f873-406d-8c36-c81221a219de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(19.5, 5.5))\n",
    "sp_g = skyproj.GnomonicSkyproj(ax=ax[0], lon_0=37.862, lat_0=6.98, min_lon_ticklabel_delta=0.2)\n",
    "sp_g.draw_hspmap(hsp_map_psf_e_g, vmin=0, vmax=pixel_psf_e_i.max())\n",
    "sp_g.ax.set_xlabel(\"RA (deg)\", fontsize=10,)\n",
    "sp_g.ax.set_ylabel(\"DEC (deg)\", fontsize=10,)\n",
    "sp_g.draw_colorbar(shrink=0.9, label='PSF Ellipticity Modulus')\n",
    "sp_g.ax.set_title(\"g-band\", pad=25)\n",
    "for seg in segs_g:\n",
    "    sp_g.ax.plot([seg[0][0], seg[1][0]], [seg[0][1], seg[1][1]], 'r-', alpha=0.6)\n",
    "\n",
    "sp_r = skyproj.GnomonicSkyproj(ax=ax[1], lon_0=37.862, lat_0=6.98, min_lon_ticklabel_delta=0.2)\n",
    "sp_r.draw_hspmap(hsp_map_psf_e_r, vmin=0, vmax=pixel_psf_e_i.max())\n",
    "sp_r.ax.set_xlabel(\"RA (deg)\", fontsize=10,)\n",
    "sp_r.ax.set_ylabel(\"DEC (deg)\", fontsize=10,)\n",
    "sp_r.draw_colorbar(shrink=0.9, label='PSF Ellipticity Modulus')\n",
    "sp_r.ax.set_title(\"r-band\", pad=25)\n",
    "for seg in segs_r:\n",
    "    sp_r.ax.plot([seg[0][0], seg[1][0]], [seg[0][1], seg[1][1]], 'r-', alpha=0.6)\n",
    "    \n",
    "sp_i = skyproj.GnomonicSkyproj(ax=ax[2], lon_0=37.862, lat_0=6.98, min_lon_ticklabel_delta=0.2)\n",
    "sp_i.draw_hspmap(hsp_map_psf_e_i, vmin=0, vmax=pixel_psf_e_i.max())\n",
    "sp_i.ax.set_xlabel(\"RA (deg)\", fontsize=10,)\n",
    "sp_i.ax.set_ylabel(\"DEC (deg)\", fontsize=10,)\n",
    "sp_i.draw_colorbar(shrink=0.9, label='PSF Ellipticity Modulus')\n",
    "sp_i.ax.set_title(\"i-band\", pad=25)\n",
    "for seg in segs_i:\n",
    "    sp_i.ax.plot([seg[0][0], seg[1][0]], [seg[0][1], seg[1][1]], 'r-', alpha=0.6)\n",
    "\n",
    "plt.suptitle(\"PSF Ellipticity Distribution of the A360 Region\", size=15)\n",
    "\n",
    "plt.savefig(f'image_outputs_{meas_type}/3_band_psf_e_distribution.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8262f5d4-dd9b-411c-a376-d253a91bd8b1",
   "metadata": {},
   "source": [
    "## Investigate Patch Failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d290141-47d7-4412-b19a-7001185c6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any of the patches from running cell-based coadds failed\n",
    "for ref in butler.registry.queryDatasets('assembleCellCoadd_log', collections=cell_collection):\n",
    "    \n",
    "    # the only parts of these tracts within 0.5 radius overlap with already included patches\n",
    "    if ref.dataId['tract'] == 10704 or ref.dataId['tract'] == 10705:\n",
    "        continue\n",
    "\n",
    "    # these column of patches overlap with patches already in tract 10464\n",
    "    if ref.dataId['tract'] == 10463 and ref.dataId['patch'] in overlap_patches_10463:\n",
    "        continue\n",
    "\n",
    "    patch_log = butler.get('assembleCellCoadd_log', \n",
    "                     collections = cell_collection, \n",
    "                     instrument = 'LSSTComCam', \n",
    "                     skymap = 'lsst_cells_v1', \n",
    "                     tract = ref.dataId['tract'], \n",
    "                     patch = ref.dataId['patch'],\n",
    "                     band = 'i')\n",
    "    \n",
    "    patch_error = [log['message'] for log in patch_log.model_dump() if log['levelname'] == 'ERROR']\n",
    "    if len(patch_error) > 0:\n",
    "        print(patch_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d351eb62-468a-4117-a9cd-f7fef588e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any patches running Metadetection have failed and why\n",
    "for ref in butler.registry.queryDatasets('metadetectionShear_log', collections=collection):\n",
    "    \n",
    "    # the only parts of these tracts within 0.5 radius overlap with already included patches\n",
    "    if ref.dataId['tract'] == 10704 or ref.dataId['tract'] == 10705:\n",
    "        continue\n",
    "\n",
    "    # these column of patches overlap with patches already in tract 10464\n",
    "    if ref.dataId['tract'] == 10463 and ref.dataId['patch'] in overlap_patches_10463:\n",
    "        continue\n",
    "        \n",
    "    patch_log = butler.get('metadetectionShear_log', \n",
    "                     collections = collection, \n",
    "                     instrument = 'LSSTComCam', \n",
    "                     skymap = 'lsst_cells_v1', \n",
    "                     tract = ref.dataId['tract'], \n",
    "                     patch = ref.dataId['patch'],\n",
    "                     band = 'i')\n",
    "    \n",
    "    patch_error = [log['message'] for log in patch_log.model_dump() if log['levelname'] == 'ERROR']\n",
    "    if len(patch_error) > 0:\n",
    "        print(patch_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
